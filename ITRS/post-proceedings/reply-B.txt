We would like to thank this referee for their careful review.
A few notes are given below in reply.

> Referee report on 'Intersections and Unions of Session Types' by Cosku
> Asay and Frank Pfenning.
>
> The paper presupposes too much familiarity with the underlying process
> calculus. There is no citation for the definition of processes, where
> I can but assume that many different dialects exist.
> The paper is poorly organised: concepts are used before being
> introduced, or are not introduced at all.

An introduction to the underlying process calculus was provided in the first
two sections. We also refer to Luis Caires & Frank Pfenning (2010) and
Frank Pfenning & Dennis Griffith (2015) on which the underlying calculus
is based. We have extended this introduction to include more details
on cut and id, which are usually not addressed in other process calculi.
We hope that this significantly lowers the barrier of entry for those not
already familiar with the linear sequent calculus. Unfortunately, a complete
treatment is not possible given the space limitations without distracting
from the main contributions.

> The paper makes no comparison with other work on session types with
> intersection and union (I refer directly to Padovani's paper and
> Castagna et al's paper), which is a grave omission.

We have added explicit comparisons to these works; see Section 7.

> The definition of process syntax is confusing and incomplete. The
> notion is one I am not familiar with (coming from the Pi calculus and
> CSS), and there is no help given at all to the reader to explain the
> notation. But a more grave shortcoming is that the syntax is not the
> one used in the examples (the paper has the optimistic phrase
> 'concrete syntax (...) the mapping to abstract syntax (...) should be
> clear'; it is not)...

We have extended the introduction to the base system as mentioned above
(which should clear some of the confusion). We also explain the syntax
in more detail. In addition, we got rid of concrete syntax almost completely,
and whatever differences remain are clearly explained.

> ...and processes are allowed to be recursive whereas
> recursion is never dealt with formally. It gets introduced very
> casually on page 6, never gets linked to type assignment, and is a
> snake hiding in the grass: dealing with recursion in the context of
> intersection and union types is not straightforward, and should be
> dealt with in detail.
>
> Moreover, some (recursive!) type declarations are used without being
> introduced or even discussed. The same holds for recursive types:
> these are crucial to the paper (in fact, many example use them) and
> are only informally introduced on page 5.

We have significantly improved our treatment of recursion throughout the
paper. This was a very valid concern as the treatment of recursion
in the presence of intersections and unions is possibly the most interesting
(and challenging) part of the paper. We had apparently gone too far
in our struggle to fit the required page limit.

> Notation is haphazard and confusing: for example, first $P_x$ stands
> for a process that has $x$ as a free variable, and then processes are
> labelled with the name of the channel it 'provides'? Is this the same
> as being free? If not, why overload this notation?

We use $P_x$ only as a shorthand for substitution and to emphasize the
channel we are focusing on. We believe this increases comprehensibility,
but it is nothing more than meta-level ``syntactic sugar''. We use a
different notation to label processes with the channels they provide
(proc_c P) so there is no overloading and there shouldn't be reason for
confusion. Although the provided channel will be free in a process, this
is not the same as being free. A process might have many free channels,
as should be evident from the use of a context in typing judgements. We
tried to make these points more clear in the revised version.

> The operational semantics rules, some of which are expressed through a
> quantifier, are badly formulated.

The operational semantics is based on multiset rewriting, which is very
well-studied. However, we understand why the notation would be confusing,
and switched to a more familiar/intuitive one.

> If I understand things correctly, the $c$ in $P$ in rule $\sqcap L_i$
> occurs only once in $P$; in those rules, one of the component of the
> intersection type (say $A$) is selected for $c$, and in $P$ there is
> no further need for the other type $B$. So why have intersection types
> at all? In terms of typability, I can just use the derivation for $
> \Psi \vdash_{\eta} P :: (c:A) $ and that for $ \Psi, c:A \vdash_{\eta}
> P :: (d:D) $ to achieve the desired result. Yes, you have intersection
> types, but in terms of typability they make absolutely no
> contribution. Can you give an example of a process for which you would
> NEED intersection types? A similar observation can be made, of course,
> for union types.
>
> I do not believe that having intersection and union types in a linear
> calculus makes any sense at all.

A channel can and usually will occur multiple times in a process.
Linearity does not imply single use, it implies \emph{linear} use. We
have changed the language to try to clear up the confusion. We also
address the specific concern about intersections in the relevant section
with an example.

> Minor comments:
>
> Abstract: add 'the' to linear sequent calculus.
> Add a hyphen in equirecursive to get equi-recursive throughout the paper.

Fixed.

> Page 2: Why should the $c$ in the judgment be different from the
> $c_i$s in the context?

We make a distinction between the channels that a process uses and the one
it provides. This distinction is important to map more directly to the left
and right rules of sequent calculus.

> I'm not sure why channel name appear only once in processes? Does
> communication not take place over channels, and does that not imply
> that a channel name has to appear twice?

They can (and usually will) appear multiple times in a process. They simply
have to be used linearly. For example, all branches of a case statement will
have the same set of free variables. We could also use the same channel to send
multiple channel references along. However, after each communication, the type
of the channel changes. This is mirrored in the typing rules.

> Page 3: Explain why is it necessary to subscript a process $P$ with a
> variable name $x$ as in $P_x$ to indicate that $x$ is free in $P$.
> Also, no notion of binding has been mentioned. Can a process have more
> than one free variable? If so, is is possible that $P_x = P_y$, with
> $x \not= y$? Are processes linear over their variables as well, or can
> $x$ appear many times in $x$? The notation $P_a$ is very confusing; I
> see no reason to not record which variable has been replaced in $P$.
> Using the present notation, the identity of the variable has
> disappeared, so it is not clear which of the variables in $P$ got
> replaced by $a$ in $P_a$. Better use $P[a/x]$.

The $P_x$ notation is simply a syntactic convenience. As noted in the paper,
$P_a$ precisely means $P[a/x]$. We improved consistency in our use of the
notation.

> According to the syntax, variables are not processes themselves; can
> you explain how the interaction between processes deals with
> variables.

There are two types of variables. Channels and process variables. Channels
only occur in certain positions as determined by the syntax and typing rules.
We can only substitute channels for channels, not process expressions. There
are also process variables which stand for processes. This is used for recursive
processes. We deal with process variables more formally in the revised version.

> What is the fourth column in the 'definition' of the syntax about?
> Types? Intuition? How is 'id' the same as 'forward'?

These are the corresponding types which and are meant to provide operational
intuition. This is made formal by typing rules of course. We have also
added a paragraphs explaining the syntax. id and forwarding are identified
through the Curry-Howard correspondence. See the extended introduction.

> In the definition of syntax, it would be helpful to give a brief
> explanation of the notation used. For example, how should I read $x
> \leftarrow P_x;Q_x$ of $send c (y \leftarrow P_y);Q$?

Added a paragraph on intuitive readings of process.

> Why are there backquotes in the 'concrete' syntax? It seems that the
> semicolon is used also for some kind of sequential composition between
> processes, which is missing from the syntax definition.

We had used backquotes to emphasize channel names to improve readability. We
got rid of this (along with concrete syntax) since it apparently only lead to
confusion. The semicolons are present in the abstract syntax also.
It is slightly different from a sequential composition since they are built
into the expressions and we cannot combine arbitrary expressions this way.

> 2.2 Write 'Section 3.3'

We're not sure what this is referring to...

> Figure 1: Should you not have used $P_d$ also in the premise of rule
> $\otimes R$?

Fixed.

> Page 4: In rule $config_1$, what is $\vdash_0$? And what is $\Omega
> \models \Psi$? How can there be more that one statement after
> $\models$, and why should $\Omega$ 'satisfy' all of $\Psi$, and is it
> not enough that it satisfies one of the statements?

We have sets of processes to the left of :: and sets of types channels to
the right of ::. We need to satisfy all channels in a context.

> Page 5: What reason is there to use the lollipop arrow also for
> reduction and the $\oplus$ for process composition? This only creates
> confusion and serves no real purpose.

These are multiset rewriting rules. We transition from one state containing
certain processes to another, but these processes are ``used up''. Linear
logic (and this linear connectives) are perfect for capturing such ``resource''
usage. Alas, it is clear that this is leading to confusion, so we have changed
the notation.

> What is that existential quantifier doing in the operational
> semantics? Does the process run to True or False? Are these
> conditional rules? Is $a$ produced by an oracle? There is some $a$,
> but we do not know which one?

It simply indicated that the channel is fresh. Within the context of this
paper, it suffices to think that this is equivalent to writing ``where $a$
is fresh'' as a side condition (which is what exactly what we do in the
new notation).

> 'which means there are no explicit term level coercions': this is
> incorrect. Identifying $\mu t.A$ and $A[\mu t . A / t]$ has nothing to
> do with having fold and unfold. In the iso-recursive system you have
> those syntactic markers, in the equi one you do not.

I believe we are saying the same thing. There are coercions in the iso-recursive
approach and no coercions in the equi-recursive. This probably comes down to what
we mean by ``identify'', which is similar to the distinction between definitional
and propositional equality in dependent type theories for example.

> Page 6: 'which is parameterised over channels ... to allow renaming':
> I have no idea what you mean by that.
>
> Last line: Section 2.1
>
> Page 7: 'should be interpreted coinductively' The only reason this is
> the case is because of recursive types, but the rules dealing with
> those are omitted. I find this worrying.

We have changed (and significantly improved) the way we handle recursive types.

> Page 7-8 'It is important to note that we restore (...) our use of the
> linear sequent calculus' This is quite a strong claim to make that
> does not get substantiated at all. I strongly suspect that you have
> flattened the calculus so much that the problem disappears, not that
> you have solved it.

This is meant more as an observation rather than a grand claim. The problem
goes away because the calculus is better behaved (the problem with unions also
does not arise in languages without effects, for example). I will disagree with
the statement that we flattened the calculus *too* much (this ties in to the previous
comments about the strength of the calculus). We did change the language though,
which was misleading.

> Page 8: It would be good to see a derivation for the example on page 8.
>
> Why not add $Nat \leq Even \sqcup Odd$ to the type declarations? If
> you allow user defined types, why not user defined subtypes?

I don't think arbitrary user defined subtypes would be sound unless you
take the proper precautions (e.g. coercive subtyping). The subtyping relation
is implies by the structure of the type.

> 'Note that checking (...) rather than infer the least one'. You are
> taking a big leap of faith here. Not only have you not presented any
> notion of type checking (so far). What is the 'bidirectional nature of
> our system'?  How can the type checker 'check a fixed point'? This is
> all far too vague and imprecise.

This should be more clear after our improvements to the handling of recursion.
Also fixed the language.

> Section 4.3: why is in interesting to have these distributivity laws
> in the system? What problem is solved by making sure they are allowed?

The bigger problem is they are admissible one way but not the other. So
depending on how you spell-out your types, processes may or may not
type-check even though the two types are semantically equivalent. It
would be nice to have a complete semantic characterization so that the
type-system would identify those types that are semantically equivalent,
but that seems challenging in the presence of higher-order types.

> Page 10: 'at which point we non-deterministically pick'; what if you
> pick the wrong one? Do you back-track, and pick another? Is this an
> exhaustive search?

Non-deterministic (as opposed to arbitrary or random) choice implies
backtracking. We state this explicitly now.

> Page 11: How can 'one of the types in $A \leq B$ be free? How do you
> bind a type?

Meaning one type is fixed by the typing rule but the other can be anything.
Made this more clear in the text.

> 'Rules for recursive processes (...) than a single type.' I have not
> found a single rule for recursion in the paper.

Fixed.

> Theorem 5.1 What is 'suitably converted'? You cannot state a theorem
> through handwaving.

Fixed.

> Figure 3: I would expect that at least these rules would deal with
> recursion, but alas, no.

Fixed.

