We would like to thank this referee for their careful review.
A few notes are given below in reply.

> Referee report on 'Intersections and Unions of Session Types' by Cosku
> Asay and Frank Pfenning.
>
> The paper presupposes too much familiarity with the underlying process
> calculus. There is no citation for the definition of processes, where
> I can but assume that many different dialects exist.
> The paper is poorly organised: concepts are used before being
> introduced, or are not introduced at all.

An introduction to the underlying process calculus is provided in the first
two sections. We also refer to Luis Caires & Frank Pfenning (2010) and
Frank Pfenning & Dennis Griffith (2015) on which the underlying calculus
is based. Unfortunately, a complete treatment is not possible given the
space limitations without distracting from the main contributions.

TODO: maybe the references weren't clear?

> The paper makes no comparison with other work on session types with
> intersection and union (I refer directly to Padovani's paper and
> Castagna et al's paper), which is a grave omission.

We have added explicit comparisons to these works; see Section 7.

> The definition of process syntax is confusing and incomplete. The
> notion is one I am not familiar with (coming from the Pi calculus and
> CSS), and there is no help given at all to the reader to explain the
> notation. But a more grave shortcoming is that the syntax is not the
> one used in the examples (the paper has the optimistic phrase
> 'concrete syntax (...) the mapping to abstract syntax (...) should be
> clear'; it is not) and processes are allowed to be recursive whereas
> recursion is never dealt with formally. It gets introduced very
> casually on page 6, never gets linked to type assignment, and is a
> snake hiding in the grass: dealing with recursion in the context of
> intersection and union types is not straightforward, and should be
> dealt with in detail.

TODO: is the process syntax confusing?
We have changed the concrete syntax to more closely mirror the abstract
syntax, and added explanations for the minor differences.
TODO: expand the section on recursive types?

> Moreover, some (recursive!) type declarations are used without being
> introduced or even discussed. The same holds for recursive types:
> these are crucial to the paper (in fact, many example use them) and
> are only informally introduced on page 5.

TODO:

> Notation is haphazard and confusing: for example, first $P_x$ stands
> for a process that has $x$ as a free variable, and then processes are
> labelled with the name of the channel it 'provides'? Is this the same
> as being free? If not, why overload this notation?

We use $P_x$ only as a shorthand for substitution and to emphasize the
channel we are focusing on. We believe this increases comprehensibility,
but it is nothing more than meta-level ``syntactic sugar''. We use a
different notation to label processes with the channels they provide
(proc_c P) so there is no overloading and there shouldn't be reason for
confusion. Although the provided channel will be free in a process, this
is not the same as being free. A process might have many free channels,
as should be evident from the use of a context in typing judgements.

> The operational semantics rules, some of which are expressed through a
> quantifier, are badly formulated.

The operational semantics is based on multiset rewriting, which is very
well-studies. See the references. In addition, an intuitive reading is
provided, which should be sufficient for understanding paper.

> If I understand things correctly, the $c$ in $P$ in rule $\sqcap L_i$
> occurs only once in $P$; in those rules, one of the component of the
> intersection type (say $A$) is selected for $c$, and in $P$ there is
> no further need for the other type $B$. So why have intersection types
> at all? In terms of typability, I can just use the derivation for $
> \Psi \vdash_{\eta} P :: (c:A) $ and that for $ \Psi, c:A \vdash_{\eta}
> P :: (d:D) $ to achieve the desired result. Yes, you have intersection
> types, but in terms of typability they make absolutely no
> contribution. Can you give an example of a process for which you would
> NEED intersection types? A similar observation can be made, of course,
> for union types.
>
> I do not believe that having intersection and union types in a linear
> calculus makes any sense at all.

TODO:


> Minor comments:
> 
> Abstract: add 'the' to linear sequent calculus.

OK.

> Add a hyphen in equirecursive to get equi-recursive throughout the paper.

I believe both spellings are correct.

> Page 2: Why should the $c$ in the judgment be different from the
> $c_i$s in the context?

We make a distinction between the channels that a process uses and the one
it provides. This distinction is important to map more directly to the left
and right rules of sequent calculus.

> I'm not sure why channel name appear only once in processes? Does
> communication not take place over channels, and does that not imply
> that a channel name has to appear twice?

They can (and usually will) appear multiple times in a process. They simply
have to be used linearly. For example, all branches of a case statement will
have the same set of free variables. We could also the same channel to send
multiple channel references along. However, after each communication, the type
of the channel changes. This is mirrored in the typing rules.

> Page 3: Explain why is it necessary to subscript a process $P$ with a
> variable name $x$ as in $P_x$ to indicate that $x$ is free in $P$.
> Also, no notion of binding has been mentioned. Can a process have more
> than one free variable? If so, is is possible that $P_x = P_y$, with
> $x \not= y$? Are processes linear over their variables as well, or can
> $x$ appear many times in $x$? The notation $P_a$ is very confusing; I
> see no reason to not record which variable has been replaced in $P$.
> Using the present notation, the identity of the variable has
> disappeared, so it is not clear which of the variables in $P$ got
> replaced by $a$ in $P_a$. Better use $P[a/x]$.

The $P_x$ notation is simply a syntactic convenience. As noted in the paper,
$P_a$ precisely means $P[a/x]$.
TODO: should we get rid of this? He has a point.

> According to the syntax, variables are not processes themselves; can
> you explain how the interaction between processes deals with
> variables.

There are two types of variables. Channels and process variables. Channels
only occur in certain positions as determined by the syntax and typing rules.
We can only substitute channels for channels, not process expressions. There
are also process variables which stand for processes. This is used for recursive
processes.

> What is the fourth column in the 'definition' of the syntax about?
> Types? Intuition? How is 'id' the same as 'forward'?

These are the corresponding types which is meant to provide operational
intuition. This is made formal by typing rules of course. We have also
added a paragraphs explaining the syntax. id and forwarding are identified
through the Curry-Howard correspondence. See the typing rule.

> In the definition of syntax, it would be helpful to give a brief
> explanation of the notation used. For example, how should I read $x
> \leftarrow P_x;Q_x$ of $send c (y \leftarrow P_y);Q$?

Added a paragraph on intuitive readings of process.

> Why are there backquotes in the 'concrete' syntax? It seems that the
> semicolon is used also for some kind of sequential composition between
> processes, which is missing from the syntax definition.

We use backquotes to emphasize channel names to ease understanding. This is now
noted in a footnote. The semicolons are present in the abstract syntax also.
It is different from a sequential composition since they are built into the
expressions and we cannot combine arbitrary expressions this way.

> 2.2 Write 'Section 3.3'

TODO: not sure what this means.

> Figure 1: Should you not have used $P_d$ also in the premise of rule
> $\otimes R$?

Fixed.

> Page 4: In rule $config_1$, what is $\vdash_0$? And what is $\Omega
> \models \Psi$? How can there be more that one statement after
> $\models$, and why should $\Omega$ 'satisfy' all of $\Psi$, and is it
> not enough that it satisfies one of the statements?

We have sets of processes to the left of :: and sets of types channels to
the right of ::. We need to satisfy all channels in a context.

> Page 5: What reason is there to use the lollipop arrow also for
> reduction and the $\oplus$ for process composition? This only creates
> confusion and serves no real purpose.

These are multiset rewriting rules. We transition from one state containing
certain processes to another, but these processes are ``used up''. This can
be perfectly captured using linear connectives.

> What is that existential quantifier doing in the operational
> semantics? Does the process run to True or False? Are these
> conditional rules? Is $a$ produced by an oracle? There is some $a$,
> but we do not know which one?

It simply indicated that the channel is fresh. Within the context of this
paper, it suffices to think that this is equivalent to writing ``where $a$
is fresh'' as a side condition. But the existential quantifier is a more
principled way of doing it (see Robert Simmons' PhD thesis (2012) for details).

> 'which means there are no explicit term level coercions': this is
> incorrect. Identifying $\mu t.A$ and $A[\mu t . A / t]$ has nothing to
> do with having fold and unfold. In the iso-recursive system you have
> those syntactic markers, in the equi one you do not.

I believe we are saying the same thing. There are coercions in the iso-recursive
approach and no coercions in the equi-recursive. This probably comes down to what
we mean by ``identify'', which is similar to the distinction between definitional
and propositional equality in dependent type theories.

> Page 6: 'which is parameterised over channels ... to allow renaming':
> I have no idea what you mean by that.

TODO: do recursive types better.

> Last line: Section 2.1
> 
> Page 7: 'should be interpreted coinductively' The only reason this is
> the case is because of recursive types, but the rules dealing with
> those are omitted. I find this worrying.

TODO: do recursive types better.

> Page 7-8 'It is important to note that we restore (...) our use of the
> linear sequent calculus' This is quite a strong claim to make that
> does not get substantiated at all. I strongly suspect that you have
> flattened the calculus so much that the problem disappears, not that
> you have solved it.

This is meant more as an observation rather than a grand claim. The problem
goes away because the calculus is better behaved (the problem with unions also
does not arise in languages without effects, for example). I will disagree with
the statement that we flattened calculus too much (this ties in to the previous
comments about the strength of the calculus). We did change the language though,
which was misleading.

> Page 8: It would be good to see a derivation for the example on page 8.
>
> Why not add $Nat \leq Even \sqcup Odd$ to the type declarations? If
> you allow user defined types, why not user defined subtypes?
> 
> 'Note that checking (...) rather than infer the least one'. You are
> taking a big leap of faith here. Not only have you not presented any
> notion of type checking (so far). What is the 'bidirectional nature of
> our system'?  How can the type checker 'check a fixed point'? This is
> all far too vague and imprecise.

TODO

> Section 4.3: why is in interesting to have these distributivity laws
> in the system? What problem is solved by making sure they are allowed?

The bigger problem is they are admissible one way but not the other. So
depending on how you spell-out your types, processes may or may not
type-check even though the two types are semantically equivalent. It
would be nice to have a complete semantic characterization so that the
type-system would identify those types that are semantically equivalent,
but that seems challenging in the presence of higher-order types.

> Page 10: 'at which point we non-deterministically pick'; what if you
> pick the wrong one? Do you back-track, and pick another? Is this an
> exhaustive search?

Non-deterministic (as opposed to arbitrary or random) choice implies
backtracking.

> Page 11: How can 'one of the types in $A \leq B$ be free? How do you
> bind a type?

Meaning one type is fixed by the typing rule but the other can be anything.
Made this more clear in the text.

> 'Rules for recursive processes (...) than a single type.' I have not
> found a single rule for recursion in the paper.

TODO: fix

> Theorem 5.1 What is 'suitably converted'? You cannot state a theorem
> through handwaving.

TODO

> Figure 3: I would expect that at least these rules would deal with
> recursion, but alas, no.

TODO:

