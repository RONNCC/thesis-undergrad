\documentclass[a4paper,USenglish]{lipics-v2016}
% for section-numbered lemmas etc., use "numberwithinsect"

\usepackage{microtype}%if unwanted, comment out or use option "draft"
\usepackage{proof}
\usepackage{mathpartir}

\usepackage{todonotes}

\newcommand\indexVar{x}
\newcommand\lab{lab}

\usepackage{macro/generic}
\usepackage[index=\indexVar,label=\lab]{macro/language}
\usepackage{macro/code}

\bibliographystyle{plainurl}

% Author macros::begin %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{Refinements for Session-typed Concurrency\footnote{This research was supported in part by NSF grant CNS1423168.}}
%\titlerunning{Refinements for Session-typed Concurrency}

\author[1]{Co\c{s}ku Acay}
\author[2]{Frank Pfenning}
\affil[1]{Carnegie Mellon University, Pittsburgh, PA 15213 \\
  \texttt{cacay@cmu.edu}}
\affil[2]{Carnegie Mellon University, Pittsburgh, PA 15213 \\
  \texttt{fp@cs.cmu.edu}}
\authorrunning{C. Acay and F. Pfenning} %mandatory. First: Use abbreviated first/middle names. Second (only in severe cases): Use first author plus 'et. al.'

\Copyright{Cosku Acay}%mandatory, please use full first names. LIPIcs license is "CC-BY";  http://creativecommons.org/licenses/by/3.0/

\subjclass{D.3.2 Language Classifications}% mandatory: Please choose ACM 1998 classifications from http://www.acm.org/about/class/ccs98-html . E.g., cite as "F.1.1 Models of Computation". 
\keywords{Dummy keyword -- please provide 1--5 keywords}% mandatory: Please provide 1-5 keywords
% Author macros::end %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%Editor-only macros:: begin (do not touch as author)%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\EventEditors{John Q. Open and Joan R. Acces}
\EventNoEds{2}
\EventLongTitle{42nd Conference on Very Important Topics (CVIT 2016)}
\EventShortTitle{CVIT 2016}
\EventAcronym{CVIT}
\EventYear{2016}
\EventDate{December 24--27, 2016}
\EventLocation{Little Whinging, United Kingdom}
\EventLogo{}
\SeriesVolume{42}
\ArticleNo{23}
% Editor-only macros::end %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle

\begin{abstract}
Prior work has explored the deep connection between linear sequent calculus and session-typed message-passing concurrent computation by combining equirecursive types with a natural notion of subtyping. In this paper, we extend this further by intersection and union types in order to express multiple behavioral properties of processes in a single type. In the resulting system, we can represent internal and external choice by intersection and union, as first suggested by Padovani for a different system of session types.
\todo{Better abstract.}
\end{abstract}

 \todo{Find best subjclass}
 \todo{Pick keywords}

\section{Typesetting instructions -- please read carefully}
\begin{itemize}
\item Fill out the \verb+\subjclass+ and \verb+\keywords+ macros. For the \verb+\subjclass+, please refer to the ACM classification at \url{http://www.acm.org/about/class/ccs98-html}.
\item Take care of suitable linebreaks and pagebreaks. No overfull \verb+\hboxes+ should occur in the warnings log.
\end{itemize}


\section{Introduction}

Prior work has established a Curry-Howard correspondence between intuitionistic linear sequent calculus and session-typed message-passing concurrency \cite{CairesP10, PfenningG15, Honda93}. In this formulation, linear propositions are interpreted as session-types, proofs as processes, and cut elimination as communication. Session types are assigned to channels and prescribe the communication behaviour along them. Each channel is offered by a unique process and used by exactly one, which is where linearity comes in. When the behaviour along a channel $c$ satisfies the type $A$ and $P$ is the process that offers along $c$, we say that $P$ provides along $c$ the type $A$.

In the base system, each type directly corresponds to process of a certain form. For example, a process providing the type $A \tensor B$ first sends out a channel satisfying $A$, then acts as $B$. Similarly, a process offering $\terminate$ sends the label $\irb{end}$ and terminates. We call these \emph{structural} types since they correspond to processes of a certain structure. In this paper, we extend the base type system with intersections and unions. We call these \emph{property} types since they do not correspond to specific forms of processes in that any process may be assigned such a type. In addition, if we interpret a type as specifying a property, then intersection corresponds to satisfying two properties simultaneously and union corresponds to satisfying one or the other. When types are interpreted as sets, intersection and union are set theoretic intersection and union. \todo{I don't think I need the set theoretic interpretation, but there are many ways to think about intersections and unions. Which ones are important?}

Our goal is to show that the base system extended with intersection, unions, recursive types, and a natural notion of subtyping is type safe. We do this by proving the usual type preservation and progress theorems, which correspond to session fidelity and deadlock freedom in the concurrent context. In the presence of a strong subtyping relation and transparent (i.e.\ non-generative)  equirecursive types, intersections and unions turn out to be powerful enough to specify many interesting communications behaviours, which we demonstrate with concrete examples and by analogy to \cite{FreemanP91}.

Our contributions are summarized below:
\begin{itemize}
  \item We introduce intersection and union types to a session-typed concurrent calculus and prove standard type preservation and progress theorems.
  \item We give a simple and sound coinductive subtyping relation in the presence of equirecursive types, intersections, and unions reminiscent of Gentzen's multiple conclusion logic \cite{Gentzen35, Girard87}.
  \item We show how intersections and unions can be used as refinements of recursive types in the style of \cite{FreemanP91} in a linear setting.
  \item We show that subtyping and type checking are decidable by presenting an algorithmic system.
  \item We demonstrate how certain structural type constructs (i.e.\ internal and external choices) can be understood as singletons interacting with intersection and union.
\end{itemize}

Some aspects that would be important in a full accounting of the system but are left out for the sake of conciseness are as follows:
\begin{itemize}
  \item We omit discussion of an underlying functional language and only consider the process calculus. We believe the integration is orthogonal and can be found elsewhere \cite{ToninhoCP13}.
  \item We do not consider shared/unrestricted channels and believe they are a simple extension \cite{CairesP10}.
  \item Asynchronous communication does not depend on the specifics of the type system and should be trivial \cite{CairesP10}.
  \item Polymorphism and abstract types are not in the system. Depending on the specifics, polymorphism can be tricky in the presence of equirecursive types and requires some care. \todo{Citation.}
\end{itemize}

The rest of this paper is structured as follows. In section~\ref{base}, we formally introduce the base system and explore the correspondence between linear logic and session types more. Section~\ref{recursive} extends the base system with recursive types and a natural notion of coinductive subtyping. Section~\ref{refinements} is where our contribution starts. We add intersections and unions and modify the subtyping relation to handle distributivity cleanly. Section~\ref{metatheory} discusses the metatheory, section~\ref{algorithmic} gives an algorithmic system for type-checking, and finally, section~\ref{conclusion} concludes.


\section{From Linear Logic to Session Types}
\label{base}
We only give a brief review of linear logic and its connection to session types here. Interested readers are referred to \cite{CairesP10, PfenningG15, Honda93}. The key idea of linear logic is to treat logical propositions as resources: each must be used \emph{exactly} once. In the intuitionistic setting, this is written as a linear hypothetical judgement:
$$ A_1, \ldots, A_n \vdash A $$
where $A_1$ through $A_n$ are the hypothesis that must be used exactly once in the proof of $A$. The order of hypothesis is irrelevant, so they are treated as a (multi) set. According to the Curry-Howard isomorphism for intuitionistic linear logic, propositions are interpreted as session types, proofs as concurrent processes, and cut elimination as communication. For this correspondence, hypothesis are labelled with channels (rather than with variables). We also assign a channel name to the conclusion since processes are not evaluated like in a functional language but are communicated with (along a channel). This leads to the following judgement:
$$ \typeD {c_1 : A_1, \ldots, c_n : A_n} P c A$$
which should be interpreted as ``$P$ offers along the channel $c$ the session $A$ using channels $c_1, \ldots, c_n$ with the corresponding types''. We assume $c_1, \ldots, c_n$ and $c$ are all distinct.

Each process offers along a specific channel, and in the linear setting, each channel must be used exactly in one place. Processes cannot rename channels, which suggests that channel names act as unique process identifiers.

Within this framework, the $\cut$ rule corresponds to a form of process composition where the main process (client) spawns off a helper process (provider) which it can communicate with from then on:
$$ \infer[\cut]{ \typeD {\ctx, \ctx'} {\tspawn{c}{P_c}{Q_c}} {d} {D} }
    { \typeD {\ctx} {P_c} {c} {A}
    & \typeD {\ctx', c : A} {Q_c} {d} {D}
    }
$$
\todo{Mention the system is different from $\pi$ calculus?}

Working out the isomorphism further and assigning a session type to each linear proposition gives the following interpretation:

\begin{center}
\begin{tabular}{l c l l}
  $A, B, C$ & ::= & $\terminate$        & send \texttt{end} and terminate \\
            & $|$ & $A \tensor B$       & send channel of type $A$ and continue as $B$ \\
            & $|$ & $\internals{A}{I}$  & send $\lab_i$ and continue as $A_i$ \\
            & $|$ & $\tau \sendVal B$   & send value of type $\tau$ and continue as $B$ \\
            & $|$ & $A \lolli B$        & receive channel of type $A$ and continue as $B$ \\
            & $|$ & $\externals{A}{I}$  & receive $\lab_i$ and continue as $A_i$ \\
            & $|$ & $\tau \recvVal B$   & receive value of type $\tau$ and continue as $B$
\end{tabular}
\end{center}

The process with trivial behaviour is typed by $\terminate$. $A \tensor B$ and $A \lolli B$ correspond to sending and receiving channel names respectively. $\tau \sendVal B$ and $\tau \recvVal B$ are similar, but values in some underlying functional language are exchanged rather than channels. We will ignore these types for the sake of conciseness and focus on the process calculus. The integration of a functional language is orthogonal and can be found in \cite{ToninhoCP13}.

Possibly the more interesting types are $\internals A I$ and $\externals A I$ which are generalizations of the binary additive disjunction ($\internal$) and conjunction ($\external$). $\internals A I$ is called an internal choice, since the label is picked by the provider (we always consider the world from the provider's perspective). In the same vein, $\externals A I$ is an external choice since the choice is made externally by the client. In either case, $I$ is a \emph{finite} index set, $\lab : I \to \labels$ is an \emph{injective} function into the set of labels, and $A : I \to \types$ is any function into types. The order of labels does not matter and each label must be unique.


\subsection{Process Expressions}

The proof terms, or processes, corresponding to these types are given below with the sending construct followed by the receiving construct. Depending on whether the communication happens along the provided channel or one of the used channels, we get either a type or its dual. \todo{This sentence sounds wack}.

\begin{center}
\begin{tabular}{l c l l}
  $P, Q, R$ & ::= & $\tspawn{x}{P_x}{Q_x}$     & cut (spawn) \\
            & $|$ & $\tfwd c d$                & id (forward) \\
            & $|$ & $\tclose c \mid \twait c P$  & $\terminate$ \\
            & $|$ & $\tsend{c}{y}{P_y}{Q} \mid \trecv{x}{c}{R_x}$ & $A \tensor B,$ $A \lolli B$ \\
            & $|$ & $\tselect{c}{}{P} \mid \tcase c {\tbranches Q i}$  & $\externals A I,$ $\internals A I$ \\
            & $|$ & $\tsendVal{c}{M}{Q} \mid \trecvVal{n}{c}{R_n}$ & $A \sendVal B,$ $A \recvVal B$
\end{tabular}
\end{center}

An example program will give more intuition about the system. We will look at process level natural numbers, which will also be our running example in this paper. Note that we will use concrete syntax, but the mapping to abstract syntax presented above should be clear. Also, this example (and almost any interesting one) requires recursive types, which are introduced in the next section. However, it should be good enough to give some intuition.

First, we define the interface:

\begin{lstlisting}[language=krill, style=custom]
  type Nat = +{zero : 1, succ : Nat}
\end{lstlisting}

This states a process level natural number is an internal choice of either zero or a successor of another natural. Next, we define two simple processes that implement the interface:

\begin{minipage}{.48\textwidth}
\begin{lstlisting}[language=krill, style=custom]
  zero : Nat
  `c <- zero = do
    `c.zero
    close `c
\end{lstlisting}
\end{minipage}
\hfill
\begin{minipage}{.48\textwidth}
\begin{lstlisting}[language=krill, style=custom]
  succ : Nat -o Nat
  `c <- succ `d = do
    `c.succ
    `c <- `d
\end{lstlisting}
\end{minipage}

\texttt{zero} simply sends the label \texttt{zero} and terminates, whereas \texttt{suc} appends a successor to the given process. \todo{Explain or remove do notation}. Here is a slightly more complicated example that doubles the given natural:

\begin{lstlisting}[language=krill, style=custom]
  double : Nat -o Nat
  `c <- double `d =
    case `d of
      zero -> do wait `d; `c.zero; close `c
      succ -> do `c.succ; `c.succ; `c <- double `d
\end{lstlisting}

These are very simple examples, though we hope they offer some insight into the system. We will expand on these example when we introduce intersections and unions, and give more interesting ones at the end once we have the whole system.


\subsection{Type Assignment for Processes}

The typing rules for other constructs are derived from linear logic by decorating derivations with proof terms just as we did with $\cut$. The rules are given in Figure~\ref{session-assignment}. \todo{Talk more about these maybe?} \todo{Should they go into the Appendix.}

\begin{rules}[session-assignment]{Type assignment for process expressions}
  % id and cut
  \infer[\id]{ \typeD {c : A} {\tfwd{d}{c}} {d} {A} }
    {}
  \and \infer[\cut]{ \typeD {\ctx, \ctx'} {\tspawn{c}{P_c}{Q_c}} {d} {D} }
    { \typeD {\ctx} {P_c} {c} {A}
    & \typeD {\ctx', c : A} {Q_c} {d} {D}
    }
  % Terminate
  \and \infer[\terminate\Right]{\typeD{\emptyCtx}{\tclose c}{c}{\terminate}}
    {}
  \and \infer[\terminate\Left]{\typeD{\ctx, c : \terminate}{\twait c P}{d}{A}}
    {\typeDJ{P}{d}{A}}
  % Tensor
  \and \infer[\tensor\Right]{\typeD{\ctx, \ctx'}{\tsend{c}{d}{P_d}{Q}}{c}{A \tensor B}}
    { \typeD{\ctx}{P}{d}{A}
    & \typeD{\ctx'}{Q}{c}{B}
    }
  \and \infer[\tensor\Left]{ \typeD{\ctx, c : A \tensor B}{\trecv{d}{c}{P_d}}{e}{E} }
    { \typeD{\ctx, d : A, c : B}{P_d}{e}{E} }
  % Internal choice
  \and \infer[\internal\Right]{\typeDJ { \tselect{c}{i}{P} } {c} {\internals{A}{I}} }
    { i \in I
    & \typeDJ{P}{c}{A_i}
    }
  \and \infer[\internal\Left]{ \typeD { \ctx, c : \internals{A}{I} } { \tcase{c}{\tbranches{P}{J}} } {d} {D} }
   { I \subseteq J
   & \typeD{\ctx, c : A_k}{P_k}{d}{D}~\text{for}~k\in I
   }
  % Implication
  \and \infer[\lolli\Right]{ \typeD{\ctx}{\trecv{d}{c}{P_d}}{c}{A \lolli B} }
    { \typeD{\ctx, d : A}{P_d}{c}{B} }
  \and \infer[\lolli\Left]{\typeD{\ctx, \ctx', c : A \lolli B}{ \tsend{c}{d}{P_d}{Q} } {e}{E}}
    { \typeD{\ctx}{P_d}{d}{A}
    & \typeD{\ctx', c : B}{Q}{e}{E}
    }
  % External choice
  \and \infer[\external\Right]{ \typeDJ { \tcase{c}{\tbranches{P}{I}} } {c} {\externals{A}{J}} }
   { J \subseteq I
   & \typeDJ{P_k}{c}{A_k}~\text{for}~k\in J
   }
  \and \infer[\external\Left]{\typeD{\ctx, c : \externals{A}{I}} { \tselect{c}{i}{P} } {d} {D}}
    { i \in I
    & \typeD{\ctx, c : A_i}{P}{d}{D}
    }
\end{rules}


\subsection{Process Configurations}

So far in the theory, we have only considered processes in isolation. In this section, we introduce process configurations in order to talk about the interactions between multiple processes. A process configuration is simply a set of processes where each process is labelled with the channel along which it provides. We use the notation $\proc c P$ for labelling the process $P$, and require that all labels in a configuration are distinct. That is, a process configuration $\set{\proc{c_1}{P_1}, \ldots, \proc{c_n}{P_n}}$ is valid if and only if $c_1, \ldots, c_n$ are all distinct. Note that we do not require channels that occur within $P_i$ to be distinct, this is handled by the typing judgement given next.

With the above restriction, each process offers along a specific channel and each channel is offered by a unique process. Since channels are linear resources in our system, they must be used by exactly one process. In addition, we do not allow cyclic dependence, which imposes an implicit forest (set of trees) structure on a process configuration where each node has one outgoing edge (including the root nodes which have ``phantom'' edges) and any number of incoming edges that correspond to channels the process uses. This observation suggests the typing rules in Figure \ref{configuration-typing}, which mimic the structure of a multi-way tree, for a process configuration.

\begin{rules}[configuration-typing]{Configuration Typing}
  \infer[\confOne]{\provides{\config, \proc c P}{c}{A}}
   { \typeRecD \ctx \emptyset P c A
   & \providesCtx \config \ctx
   }

   \and \infer[\confN]{\providesCtx {\config_1, \ldots, \config_n} {\parens{c_1 : A_1, \ldots, c_n : A_n}}}
    { \provides {\config_i} {c_i} {A_i} ~\text{for}~ i \in \set{1, \ldots, n}
    & i = 0 \vee i > 1
    }
\end{rules}

This definition is well-founded since the size of the configuration gets strictly smaller. The rules only expose the types of the roots since this is the only information we need when typing the next level. At the top level, we will usually start with one process with type $\terminate$, which will spawn off providers as needed using $\cut$. Since we do not care about the specific type at the top level, we say a process configuration $\config$ is well typed if $\providesCtx \config \ctx$ for some $\ctx$. Finally, note that the rules do not allow cyclic uses of channel names, and that the left of the turnstile is empty since configurations must be closed.


\subsection{Operational Semantics}

A process configuration evolves over time when a process takes a step (forwarding and cut step without communication) or when two matching processes communicate. For example, the processes configuration $\config, \proc c {\tclose c}, \proc d {\twait c P}$ can step to $\config, \proc d P$. We can express the rules guiding such transitions as \emph{substructural operational semantics} \cite{Simmons12} which are based on \emph{multiset rewriting} \cite{Cervesato06}. For example, the above rule is written as:
$$ \proc{c}{\tclose{c}} \otimes \proc{d}{\twait{c}{P}} \lolli \monad{\proc{d}{P}}. $$
Note that the rule is written using linear connectives, however, these should not be confused with connectives we used for types. Instead, $\tensor$ should be interpreted as conjunctions, and $\lolli$ marks transition rules. So, $A \tensor B \tensor C \lolli D \tensor E$ would mean we could replace the resources $A, B, C$ together to get a $D, E$. The curly braces $\braces \ldots$ indicated a monad which essentially forces the rules to be interpreted as a multiset rewriting rule \todo{Citation}. The rest of the rules are given in Figure \ref{operational}.

\begin{figure}[!ht]
  \centering
\begin{align*}
  % Id
  \irb{id}     \hspace{1em} & : \proc{c}{\tfwd{c}{d}} \lolli \monad{c = d} \\
  % Cut
  \irb{cut}    \hspace{1em} & : \proc{c}{\tspawn{x}{P_x}{Q_x}}
      \lolli \monad{\exists a. \proc{a}{P_a} \otimes \proc{c}{Q_a}} \\
  % One
  \irb{one} \hspace{1em} & : \proc{c}{\tclose{c}} \otimes \proc{d}{\twait{c}{P}}
    \lolli \monad{\proc{d}{P}} \\
  % Tensor
  \irb{tensor} \hspace{1em} & : \proc{c}{\tsend{c}{x}{P_x}{Q}} \otimes \proc{e}{\trecv{x}{c}{R_x}} \\
    & \hspace{2em} \lolli \monad{ \exists a. \proc{a}{P_{a}} \otimes \proc{c}{Q} \otimes \proc{e}{R_{a}} } \\
  % Internal
  \irb{internal} \hspace{1em} & : \proc{c}{\tselect{c}{i}{P}} \otimes \proc{d}{\tcase{c}{\tbranches Q I}} \otimes i \in I \\
    & \hspace{2em} \lolli \monad{ \proc{c}{P} \otimes \proc{d}{Q_i} } \\
  % Lolli
  \irb{lolli} \hspace{1em} & : \proc{c}{\trecv{x}{c}{P_x}} \otimes \proc{d}{\tsend{c}{x}{Q_x}{R}} \\
    & \hspace{2em} \lolli \monad{ \exists a. \proc{c}{P_{a}} \otimes \proc{a}{Q_a} \otimes \proc{d}{R} } \\
  % External
  \irb{external} \hspace{1em} & : \proc{c}{\tcase{c}{\tbranches P I}} \otimes \proc{d}{\tselect c i Q} \otimes i \in I \\
    & \hspace{2em} \lolli \monad{ \proc{c}{P_i} \otimes \proc{d}{Q} } \\
\end{align*}
\caption{Substructural operational semantics}
\label{operational}
\end{figure}


\section{Recursion and Subtyping}
\label{recursive}

Any interesting program requires the use of recursion. In fact, we used it even in our first example from the previous section. Here, we formally develop the theory of equirecursive types and recursive processes. We will also introduce (the initial version of) the subtyping judgment which is needed to deal with type equivalences induced by equirecursive types.

\subsection{Recursive Types}

We extend the language of types with a new construct:
\begin{center}
\begin{tabular}{l c l l}
  $A, B, C$ & ::= & \ldots               & everything from before \\
            & $|$ & $t$                  & type variables \\
            & $|$ & $\recursive{t}{A_t}$ & (equi)recursive type
\end{tabular}
\end{center}

Introduction of type variables means not every syntactically valid type makes sense. For example, the type $\recursive t u$ is meaningless since $u$ is not bound anywhere. We will require all types to be closed to rule out such types. This check only needs to happen at the top level since unfolding (which is the only operation we do on recursive types) maintains well-formedness.

We identify recursive types $\recursive{t}{A}$ with their unfolding $\subst{\recursive{t}{A}}{t}{A}$ which means there are no explicit term level coercions ($\mathtt{unfold}$ and $\mathtt{fold}$) to go between the two types. This is the reason they are called equirecursive as opposed to isorecursive where term level coercions would witness the isomorphism. Equirecursive types tend to make type-checking and meta-theory harder, however, they make more sense in a concurrent setting where behavior is easier to rely on than term structure. \todo{Find better explanation. Amadio has a good intro.}

In the style of \cite{AmadioC91}, we interpret recursive types as finite representations of potentially infinite $\mu$-free types through repeated unfolding. For example, the type $\recursive t {\terminate \lolli t}$ stands for $\terminate \lolli (\terminate \lolli (\terminate \lolli (\cdots )))$ and $\recursive t {t \tensor t}$ represents $(\cdots) \tensor (\cdots)$. This interpretation, however, breaks down when we have types such as $\recursive t t$ since no amount of unfolding can remove the $\mu$. To forbid such types, we introduce the standard global syntactic restriction called contractiveness and only consider contractive types from then on.


\subsubsection{Contractiveness}

Intuitively, a recursive type $\recursive t A$ is contractive if all occurrences of $t$ in $A$ are under a \emph{structural} type constructor. For example, $\recursive t {\terminate \lolli t}$ and $\recursive t {t \tensor t}$ are contractive whereas $\recursive t t$ and $\recursive t {\recursive u t}$ are not.

We formalize contractiveness using the notion of unguarded variables \cite{StoneS2005}. Unguarded variables of a type $A$, denoted $\unguarded{(A)}$, are defined inductively as follows:
\begin{align*}
  \unguarded{(\terminate)} &= \emptyset \\
  \unguarded{(A \tensor B)} &= \emptyset \\
  \unguarded{(\internals A I)} &= \emptyset \\
  \unguarded{(A \lolli B)} &= \emptyset \\
  \unguarded{(\externals A I)} &= \emptyset \\
  \unguarded{(t)} &= \set{t} \\
  \unguarded{(\recursive t A)} &= \unguarded{(A)} \setminus \set{t}
\end{align*}

A type is then said to be contractive if every occurrence of $\recursive t A$ satisfies $t \not\in \unguarded{(A)}$.


\subsection{Recursive Processes}

We introduce a new form of process expression which we write $\trec {p} {\tvector c} P_p$ which are modeled after the corecursive processes of \cite{Toninho14}. Here, $p$ is a process variable that intuitively stands for the whole expression and $\tvector c$ is an ordered list of channel names that is used to parametrize the expression over channel names. We use the notation $\tapp P {\tvector c}$ to denote specialization. Parametrization is useful in case we want to rename the provided or used channels. For instance, we will often want to spawn a copy of the overall expression: $\trec p c {\tspawn d {\tapp p d} P_d}$ where $P_d$ is some process that consumes $d$ and offers along $c$. The typing rules limit specialization to recursive processes and process variables.

We also have to extend the typing context to keep track of process variables. Note that we cannot simply add this information to the existing context since that contexts tracks channel names which are different from processes. In addition, the channel context is linear, but there is no reason to limit recursive occurrences of a process to exactly one place. We write the new judgement as $\typeRecDJ P c A$, where $\recCtx$ stores the typing context for process variables. As usual, we assume variable names in $\recCtx$ are made unique through alpha renaming. Recursive processes are typed using the rules in Figure~\ref{recursive-process}. These are the only rules that modify the process variable context, all other rules simply pass it up unchanged.

\begin{rules}[recursive-process]{Type assignment for recursive processes}
  \infer[\rec]{\typeRecDJ {\tapp {\parens*{ \trec p {\tvector y} P}} {\tvector z}} c A}
   { \typeRecD \ctx {\recCtx'} {\subst {\tvector z} {\tvector y} P} c A
   & \recCtx' = \recCtx, \typeD {\subst {\tvector y} {\tvector z} \ctx} {\tvar p {\tvector y}} {\subst {\tvector y} {\tvector z} c} A
   }

   \and \infer[\procVar]{\typeRecD {\rho{\parens \ctx}} \recCtx {\tapp p {\tvector z}} {\rho{\parens c}} A}
    {\typeDJ {\tvar p {\tvector y}} c A \in \recCtx
    & \rho{(\vartheta)} = \subst {\tvector z} {\tvector y} \vartheta
    }
\end{rules}

Note that in the definition of $\recCtx'$, $\typeD {\subst {\tvector y} {\tvector z} \ctx} {\tvar p {\tvector y}} {\subst {\tvector y} {\tvector z} c} A$ is not a typing judgement. Instead, $\recCtx$ should be thought of as nothing more than a map from variable names to four tuples containing parameter names, typing context, provided channel name, and provided type. It is necessary to store the context since channels are linear and channel types evolve over time, but the context needs to be the same at every occurrence of $p$.


\subsection{Subtyping}

Previously, we mentioned we would identify a recursive type and its unfolding, but we have not introduced any formal rules to actually implement this. One way of doing that would be to introduce a type equality judgement (written $A \typeeq B$) and add conversion rules. However, it turns out to be more practical to build this identification into a subtyping judgment (written $A \sub B$) since we already need subtyping for the refinement system (we can define $A \typeeq B$ if and only if $A \sub B$ and $B \sub A$). Subtyping, in turn, serves three purposes: (1) to identify a recursive type and its unfolding, (2) to propagate refinements and forget them as necessary (this will come later), and (3) to admit width and depth subtyping rules for $n$-ary choices which are customary in record-like calculi. The latter two goals overlap since data types are mainly constructed using $n$-ary choices and refinements are useful for describing properties of data types. Before we get into the specifics, let us look at how we make use of subtyping.

As usual, we introduce subtyping into term typing using what are called subsumption rules, which are presented in Figure~\ref{subsumption}. The right rule says that if a process is to provide a type $A$, it can always provide a more specific type $A'$. Dually, the left rule says that if a process can properly handle a more general type $A'$, then it does not hurt to make the type more specific.

\begin{rules}[subsumption]{Subsumption}
  \infer[\irb{Sub}\Right]{\typeRecDJ{P}{c}{A}}
    {\typeRecDJ{P}{c}{A'} & A' \sub A}
  \and \infer[\irb{Sub}\Left]{\typeRecD {\ctx, c : A} \recCtx P d B}
    {\typeD{\ctx, c : A'} P d B & A \sub A'}
\end{rules}

Our subtyping relation is defined coinductively rather than inductively since this admits more subtypes without breaking soundness. Using coinduction means we cannot add reflexivity and transitivity explicitly (subtyping should be a preorder on types), thus we carefully construct the rules to make sure they are admissible. Our first attempt is given in Figure~\ref{subtyping-first-system}. When we add intersections and unions, we will have to modify the relation slightly to admit (some of the) distributivity laws. \todo{I had a lot more to say about subtyping but I'm already running out of space (see thesis). Is this enough? Should I refer to the thesis?}

\begin{rules}[subtyping-first-system]{Subtyping (first-attempt)}
  % Base types
  \infer=[\Sub{\terminate}]{\terminate \sub \terminate}{}
  \and \infer=[\Sub\tensor]{A \tensor B \sub A' \tensor B'}
    {A \sub A' & B \sub B'}
  \and \infer=[\Sub\internal]{\internals{A}{I} \sub \internals{A'}{J}}
    {I \subseteq J & A_k \sub A'_k~\text{for}~k \in J}
  \and \infer=[\Sub\lolli]{A \lolli B \sub A' \lolli B'}
    {A' \sub A & B \sub B'}
  \and \infer=[\Sub\external]{\externals{A}{I} \sub \externals{A'}{J}}
    {J \subseteq I & A_k \sub A'_k~\text{for}~k \in J}
  % Recursive types
  \\ \infer=[\Sub{\rec\Right}]{A \sub \recursive t B}
    {A \sub \subst {\recursive t B} t B}
  \and \infer=[\Sub{\rec\Left}]{\recursive t A \sub B}
    {\subst {\recursive t A} t A \sub B}
\end{rules}

This concludes the discussion of the base system. In the next section, we introduce intersections, unions, and a multiple conclusion subtyping relation which constitute our main contributions.


\section{Intersections and Unions}
\label{refinements}

  \subsection{Intersection Types}

  \subsection{Union Types}

  \subsection{Subtyping}


\section{Metatheory}
\label{metatheory}

\begin{theorem}[Progress]
If $\providesCtx \config \ctx$ then either
\begin{enumerate}
  \item $\steps{\config}{\config'}$ for some $\config'$, or
  \item $\config$ is poised.
\end{enumerate}
\end{theorem}


\begin{theorem}[Preservation]
If $\providesCtx \config \ctx$ and $\steps{\config}{\config'}$ then $\providesCtx {\config'} \ctx$.
\end{theorem}


\section{Algorithmic System}
\label{algorithmic}


\section{Conclusion}
\label{conclusion}


\appendix


%%
%% Bibliography
%%


\bibliography{bibliography}



\end{document}
