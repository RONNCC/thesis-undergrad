\documentclass[a4paper,USenglish]{lipics-v2016}
% for section-numbered lemmas etc., use "numberwithinsect"

\usepackage{microtype}%if unwanted, comment out or use option "draft"

\usepackage{proof}
\usepackage{mathpartir}

\usepackage{todonotes}

\newcommand\indexVar{x}
\newcommand\lab{lab}

\usepackage{macro/generic}
\usepackage[index=\indexVar,label=\lab]{macro/language}
\usepackage{macro/code}

\bibliographystyle{plainurl}

% Author macros::begin %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{Intersections and Unions of Session Types\footnote{This research was supported in part by NSF grant CNS1423168.}}
%\titlerunning{Refinements for Session-typed Concurrency}

\author[1]{Co\c{s}ku Acay}
\author[2]{Frank Pfenning}
\affil[1]{Carnegie Mellon University, Pittsburgh, PA 15213 \\
  \texttt{cacay@cmu.edu}}
\affil[2]{Carnegie Mellon University, Pittsburgh, PA 15213 \\
  \texttt{fp@cs.cmu.edu}}
\authorrunning{C. Acay and F. Pfenning} %mandatory. First: Use abbreviated first/middle names. Second (only in severe cases): Use first author plus 'et. al.'

\Copyright{Cosku Acay}%mandatory, please use full first names. LIPIcs license is "CC-BY";  http://creativecommons.org/licenses/by/3.0/

\subjclass{F.3.3 Studies of Program Constructs; Type Structure}% mandatory: Please choose ACM 1998 classifications from http://www.acm.org/about/class/ccs98-html . E.g., cite as "F.1.1 Models of Computation".
\keywords{concurrency, session types, linear logic, intersection types, union types}% mandatory: Please provide 1-5 keywords
% Author macros::end %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%Editor-only macros:: begin (do not touch as author)%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\EventEditors{John Q. Open and Joan R. Acces}
\EventNoEds{2}
\EventLongTitle{42nd Conference on Very Important Topics (CVIT 2016)}
\EventShortTitle{CVIT 2016}
\EventAcronym{CVIT}
\EventYear{2016}
\EventDate{December 24--27, 2016}
\EventLocation{Little Whinging, United Kingdom}
\EventLogo{}
\SeriesVolume{42}
\ArticleNo{23}
% Editor-only macros::end %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle

\begin{abstract}
  Prior work has extended the deep, logical connection between linear
  sequent calculus and session-typed message-passing concurrent
  computation with equirecursive types and a natural notion of
  subtyping. In this paper, we extend this further by intersection and
  union types in order to express multiple behavioral properties of
  processes in a single type. We prove session fidelity and absence of
  deadlock and illustrate the expressive power of our system with some
  simple examples. We observe that we can represent internal and
  external choice by intersection and union, respectively, as first
  suggested by Padovani for a different language of session types
  motivated by operational rather than logical concerns.
\end{abstract}


\section{Introduction}

Prior work has established a Curry-Howard correspondence between intuitionistic linear sequent calculus and session-typed message-passing concurrency \cite{CairesP10, PfenningG15, Honda93}. In this formulation, linear propositions are interpreted as session-types, proofs as processes, and cut elimination as communication. Session types are assigned to channels and prescribe the communication behavior along them. Each channel is offered by a unique process and used by exactly one, which is ensured by linearity. When the behavior along a channel $c$ satisfies the type $A$ and $P$ is the process that offers along $c$, we say that $P$ provides a communcation of type $A$ along $c$.

In the base system, each type directly corresponds to a process of a certain form. For example, a process providing the type $A \tensor B$ first sends out a channel satisfying $A$, then acts as $B$. Similarly, a process offering $\terminate$ sends the label $\irb{end}$ and terminates. We call these \emph{structural types} since they correspond to processes of a certain structure. In this paper, we extend the base type system with intersections and unions. We call these \emph{property types} since they do not correspond to specific forms of processes in that any process may be assigned such a type. In addition, if we interpret a type as specifying a property, then intersection corresponds to satisfying two properties simultaneously and union corresponds to satisfying one or the other.

Our goal is to show that the base system extended with intersection, unions, recursive types, and a natural notion of subtyping is type-safe. We do this by proving the usual type preservation and progress theorems, which correspond to session fidelity and deadlock freedom in the concurrent context. In the presence of a strong subtyping relation and transparent (i.e.\ non-generative)  equirecursive types, intersections and unions turn out to be powerful enough to specify many interesting communications behaviors, which we demonstrate with examples analogous to those in functional languages \cite{FreemanP91,Dunfield03fossacs}.

Our contributions are summarized below:
\begin{itemize}
  \item We introduce intersection and union types to a session-typed concurrent calculus and prove session fidelity and deadlock freedom.
  \item We give a simple and sound coinductive subtyping relation in the presence of equirecursive types, intersections, and unions reminiscent of Gentzen's multiple conclusion sequent calculus \cite{Gentzen35, Girard87}.
  \item We show how intersections and unions can be used as refinements of recursive types in a linear setting.
  \item We show that subtyping and type checking are decidable by presenting an algorithmic system.
  \item We demonstrate how internal and external choice can be understood as singletons interacting with intersection and union.
\end{itemize}

Some aspects that would be important in a full accounting of the system but are left out for the sake of conciseness are as follows:
\begin{itemize}
  \item We omit discussion of an underlying functional language and only consider the process calculus. We believe the integration is orthogonal and can be found elsewhere \cite{ToninhoCP13,Toninho15phd,Griffith16phd}.
  \item We do not consider shared channels and persistent processes, which should be a straightforward extension based on prior work. \cite{CairesP10,PfenningG15}
  \item Our operational semantics is synchronous, but asynchronous communication~\cite{DeYoung12csl} is subject to the same type system~\cite{PfenningG15,Griffith16phd}.
  \item Behavioral polymorphism~\cite{Caires13esop} and abstract types are not in the system. Their interaction with subtyping, intersections and unions is an interesting avenue for future work.
\end{itemize}

The rest of this paper is structured as follows. In section~\ref{base}, we formally introduce the base system and explore the correspondence between linear logic and session types more. Section~\ref{recursive} extends the base system with recursive types and a natural notion of coinductive subtyping. Section~\ref{refinements} is where our contribution starts. We add intersections and unions and modify the subtyping relation to handle distributivity cleanly. Section~\ref{metatheory} discusses the metatheory, section~\ref{algorithmic} gives an algorithmic system for type-checking, and finally, section~\ref{conclusion} concludes.


\section{From Linear Logic to Session Types}
\label{base}
We only give a brief review of linear logic and its connection to session types here. Interested readers are referred to \cite{CairesP10, PfenningG15, Honda93}. The key idea of linear logic is to treat logical propositions as resources: each must be used \emph{exactly} once. In the intuitionistic setting, this is written as a linear hypothetical judgement:
$$ A_1, \ldots, A_n \vdash A $$
where $A_1$ through $A_n$ are the hypothesis that must be used exactly once in the proof of $A$. The order of hypothesis is irrelevant, so they are treated as a (multi) set. According to the Curry-Howard isomorphism for intuitionistic linear logic, propositions are interpreted as session types, proofs as concurrent processes, and cut elimination as communication. For this correspondence, hypothesis are labelled with channels (rather than with variables). We also assign a channel name to the conclusion since processes are not evaluated like in a functional language but are communicated with (along a channel). This leads to the following judgement:
$$ \typeD {c_1 : A_1, \ldots, c_n : A_n} P c A$$
which should be interpreted as ``$P$ offers along the channel $c$ the session $A$ using channels $c_1, \ldots, c_n$ with the corresponding types''. We assume $c_1, \ldots, c_n$ and $c$ are all distinct.

Each process offers along a specific channel, and in the linear setting, each channel must be used exactly in one place. Processes cannot rename channels, which suggests that channel names act as unique process identifiers.

Within this framework, the $\cut$ rule corresponds to a form of process composition where the main process (client) spawns off a helper process (provider) which it can communicate with from then on:
$$ \infer[\cut]{ \typeD {\ctx, \ctx'} {\tspawn{c}{P_c}{Q_c}} {d} {D} }
    { \typeD {\ctx} {P_c} {c} {A}
    & \typeD {\ctx', c : A} {Q_c} {d} {D}
    }
$$
\todo{Mention the system is different from $\pi$ calculus?}

Working out the isomorphism further and assigning a session type to each linear proposition gives the following interpretation:

\begin{center}
\begin{tabular}{l c l l}
  $A, B, C$ & ::= & $\terminate$        & send \texttt{end} and terminate \\
            & $|$ & $A \tensor B$       & send channel of type $A$ and continue as $B$ \\
            & $|$ & $\internals{A}{I}$  & send $\lab_i$ and continue as $A_i$ \\
            & $|$ & $\tau \sendVal B$   & send value of type $\tau$ and continue as $B$ \\
            & $|$ & $A \lolli B$        & receive channel of type $A$ and continue as $B$ \\
            & $|$ & $\externals{A}{I}$  & receive $\lab_i$ and continue as $A_i$ \\
            & $|$ & $\tau \recvVal B$   & receive value of type $\tau$ and continue as $B$
\end{tabular}
\end{center}

The process with trivial behavior is typed by $\terminate$. $A \tensor B$ and $A \lolli B$ correspond to sending and receiving channel names respectively. $\tau \sendVal B$ and $\tau \recvVal B$ are similar, but values in some underlying functional language are exchanged rather than channels. We will ignore these types for the sake of conciseness and focus on the process calculus. The integration of a functional language is orthogonal and can be found in \cite{ToninhoCP13}.

Possibly the more interesting types are $\internals A I$ and $\externals A I$ which are generalizations of the binary additive disjunction ($\internal$) and conjunction ($\external$). $\internals A I$ is called an internal choice, since the label is picked by the provider (we always consider the world from the provider's perspective). In the same vein, $\externals A I$ is an external choice since the choice is made externally by the client. In either case, $I$ is a \emph{finite} index set, $\lab : I \to \labels$ is an \emph{injective} function into the set of labels, and $A : I \to \types$ is any function into types. The order of labels does not matter and each label must be unique.


\subsection{Process Expressions}

The proof terms, or processes, corresponding to these types are given below with the sending construct followed by the receiving construct. Depending on whether the communication happens along the provided channel or one of the used channels, we get either a type or its dual. \todo{This sentence sounds wack}.

\begin{center}
\begin{tabular}{l c l l}
  $P, Q, R$ & ::= & $\tspawn{x}{P_x}{Q_x}$     & cut (spawn) \\
            & $|$ & $\tfwd c d$                & id (forward) \\
            & $|$ & $\tclose c \mid \twait c P$  & $\terminate$ \\
            & $|$ & $\tsend{c}{y}{P_y}{Q} \mid \trecv{x}{c}{R_x}$ & $A \tensor B,$ $A \lolli B$ \\
            & $|$ & $\tselect{c}{}{P} \mid \tcase c {\tbranches Q i}$  & $\externals A I,$ $\internals A I$ \\
            & $|$ & $\tsendVal{c}{M}{Q} \mid \trecvVal{n}{c}{R_n}$ & $A \sendVal B,$ $A \recvVal B$
\end{tabular}
\end{center}

An example program will give more intuition about the system. We will look at process level natural numbers, which will also be our running example in this paper. Note that we will use concrete syntax, but the mapping to abstract syntax presented above should be clear. Also, this example (and almost any interesting one) requires recursive types, which are introduced in the next section. However, it should be good enough to give some intuition.

First, we define the interface:

\begin{lstlisting}[language=krill, style=custom]
  type Nat = +{zero : 1, succ : Nat}
\end{lstlisting}

This states a process level natural number is an internal choice of either zero or a successor of another natural. Next, we define two simple processes that implement the interface:

\begin{minipage}{.48\textwidth}
\begin{lstlisting}[language=krill, style=custom]
  zero : Nat
  `c <- zero = do
    `c.zero
    close `c
\end{lstlisting}
\end{minipage}
\hfill
\begin{minipage}{.48\textwidth}
\begin{lstlisting}[language=krill, style=custom]
  succ : Nat -o Nat
  `c <- succ `d = do
    `c.succ
    `c <- `d
\end{lstlisting}
\end{minipage}

\texttt{zero} simply sends the label \texttt{zero} and terminates, whereas \texttt{suc} appends a successor to the given process. \todo{Explain or remove do notation}. Here is a slightly more complicated example that doubles the given natural:

\begin{lstlisting}[language=krill, style=custom]
  double : Nat -o Nat
  `c <- double `d =
    case `d of
      zero -> do wait `d; `c.zero; close `c
      succ -> do `c.succ; `c.succ; `c <- double `d
\end{lstlisting}

These are very simple examples, though we hope they offer some insight into the system. We will expand on these example when we introduce intersections and unions, and give more interesting ones at the end once we have the whole system.


\subsection{Type Assignment for Processes}

The typing rules for other constructs are derived from linear logic by decorating derivations with proof terms just as we did with $\cut$. The rules are given in Figure~\ref{session-assignment}. \todo{Talk more about these maybe?} \todo{Should they go into the Appendix.}

\begin{rules}[session-assignment]{Type assignment for process expressions}
  % id and cut
  \infer[\id]{ \typeD {c : A} {\tfwd{d}{c}} {d} {A} }
    {}
  \and \infer[\cut]{ \typeD {\ctx, \ctx'} {\tspawn{c}{P_c}{Q_c}} {d} {D} }
    { \typeD {\ctx} {P_c} {c} {A}
    & \typeD {\ctx', c : A} {Q_c} {d} {D}
    }
  % Terminate
  \and \infer[\terminate\Right]{\typeD{\emptyCtx}{\tclose c}{c}{\terminate}}
    {}
  \and \infer[\terminate\Left]{\typeD{\ctx, c : \terminate}{\twait c P}{d}{A}}
    {\typeDJ{P}{d}{A}}
  % Tensor
  \and \infer[\tensor\Right]{\typeD{\ctx, \ctx'}{\tsend{c}{d}{P_d}{Q}}{c}{A \tensor B}}
    { \typeD{\ctx}{P}{d}{A}
    & \typeD{\ctx'}{Q}{c}{B}
    }
  \and \infer[\tensor\Left]{ \typeD{\ctx, c : A \tensor B}{\trecv{d}{c}{P_d}}{e}{E} }
    { \typeD{\ctx, d : A, c : B}{P_d}{e}{E} }
  % Internal choice
  \and \infer[\internal\Right]{\typeDJ { \tselect{c}{i}{P} } {c} {\internals{A}{I}} }
    { i \in I
    & \typeDJ{P}{c}{A_i}
    }
  \and \infer[\internal\Left]{ \typeD { \ctx, c : \internals{A}{I} } { \tcase{c}{\tbranches{P}{J}} } {d} {D} }
   { I \subseteq J
   & \typeD{\ctx, c : A_k}{P_k}{d}{D}~\text{for}~k\in I
   }
  % Implication
  \and \infer[\lolli\Right]{ \typeD{\ctx}{\trecv{d}{c}{P_d}}{c}{A \lolli B} }
    { \typeD{\ctx, d : A}{P_d}{c}{B} }
  \and \infer[\lolli\Left]{\typeD{\ctx, \ctx', c : A \lolli B}{ \tsend{c}{d}{P_d}{Q} } {e}{E}}
    { \typeD{\ctx}{P_d}{d}{A}
    & \typeD{\ctx', c : B}{Q}{e}{E}
    }
  % External choice
  \and \infer[\external\Right]{ \typeDJ { \tcase{c}{\tbranches{P}{I}} } {c} {\externals{A}{J}} }
   { J \subseteq I
   & \typeDJ{P_k}{c}{A_k}~\text{for}~k\in J
   }
  \and \infer[\external\Left]{\typeD{\ctx, c : \externals{A}{I}} { \tselect{c}{i}{P} } {d} {D}}
    { i \in I
    & \typeD{\ctx, c : A_i}{P}{d}{D}
    }
\end{rules}


\subsection{Process Configurations}

So far in the theory, we have only considered processes in isolation. In this section, we introduce process configurations in order to talk about the interactions between multiple processes. A process configuration is simply a set of processes where each process is labelled with the channel along which it provides. We use the notation $\proc c P$ for labelling the process $P$, and require that all labels in a configuration are distinct. That is, a process configuration $\set{\proc{c_1}{P_1}, \ldots, \proc{c_n}{P_n}}$ is valid if and only if $c_1, \ldots, c_n$ are all distinct. Note that we do not require channels that occur within $P_i$ to be distinct, this is handled by the typing judgement given next.

With the above restriction, each process offers along a specific channel and each channel is offered by a unique process. Since channels are linear resources in our system, they must be used by exactly one process. In addition, we do not allow cyclic dependence, which imposes an implicit forest (set of trees) structure on a process configuration where each node has one outgoing edge (including the root nodes which have ``phantom'' edges) and any number of incoming edges that correspond to channels the process uses. This observation suggests the typing rules in Figure \ref{configuration-typing}, which mimic the structure of a multi-way tree, for a process configuration.

\begin{rules}[configuration-typing]{Configuration typing}
  \infer[\confOne]{\provides{\config, \proc c P}{c}{A}}
   { \typeRecD \ctx \emptyset P c A
   & \providesCtx \config \ctx
   }

   \and \infer[\confN]{\providesCtx {\config_1, \ldots, \config_n} {\parens{c_1 : A_1, \ldots, c_n : A_n}}}
    { \provides {\config_i} {c_i} {A_i} ~\text{for}~ i \in \set{1, \ldots, n}
    & i = 0 \vee i > 1
    }
\end{rules}

This definition is well-founded since the size of the configuration gets strictly smaller. The rules only expose the types of the roots since this is the only information we need when typing the next level. At the top level, we will usually start with one process with type $\terminate$, which will spawn off providers as needed using $\cut$. Since we do not care about the specific type at the top level, we say a process configuration $\config$ is well typed if $\providesCtx \config \ctx$ for some $\ctx$. Finally, note that the rules do not allow cyclic uses of channel names, and that the left of the turnstile is empty since configurations must be closed.


\subsection{Operational Semantics}

A process configuration evolves over time when a process takes a step (forwarding and cut step without communication) or when two matching processes communicate. For example, the processes configuration $\config, \proc c {\tclose c}, \proc d {\twait c P}$ can step to $\config, \proc d P$. We can express the rules guiding such transitions as \emph{substructural operational semantics} \cite{Simmons12} which are based on \emph{multiset rewriting} \cite{Cervesato06}. For example, the above rule is written as:
$$ \proc{c}{\tclose{c}} \otimes \proc{d}{\twait{c}{P}} \lolli \monad{\proc{d}{P}}. $$
Note that the rule is written using linear connectives, however, these should not be confused with connectives we used for types. Instead, $\tensor$ should be interpreted as conjunctions, and $\lolli$ marks transition rules. So, $A \tensor B \tensor C \lolli D \tensor E$ would mean we could replace the resources $A, B, C$ together to get a $D, E$. The curly braces $\braces \ldots$ indicated a monad which essentially forces the rules to be interpreted as a multiset rewriting rule \todo{Citation}. The rest of the rules are given in Figure \ref{operational}.

\begin{figure}[!ht]
  \centering
\begin{align*}
  % Id
  \irb{id}     \hspace{1em} & : \proc{c}{\tfwd{c}{d}} \lolli \monad{c = d} \\
  % Cut
  \irb{cut}    \hspace{1em} & : \proc{c}{\tspawn{x}{P_x}{Q_x}}
      \lolli \monad{\exists a. \proc{a}{P_a} \otimes \proc{c}{Q_a}} \\
  % One
  \irb{one} \hspace{1em} & : \proc{c}{\tclose{c}} \otimes \proc{d}{\twait{c}{P}}
    \lolli \monad{\proc{d}{P}} \\
  % Tensor
  \irb{tensor} \hspace{1em} & : \proc{c}{\tsend{c}{x}{P_x}{Q}} \otimes \proc{e}{\trecv{x}{c}{R_x}} \\
    & \hspace{2em} \lolli \monad{ \exists a. \proc{a}{P_{a}} \otimes \proc{c}{Q} \otimes \proc{e}{R_{a}} } \\
  % Internal
  \irb{internal} \hspace{1em} & : \proc{c}{\tselect{c}{i}{P}} \otimes \proc{d}{\tcase{c}{\tbranches Q I}} \otimes i \in I \\
    & \hspace{2em} \lolli \monad{ \proc{c}{P} \otimes \proc{d}{Q_i} } \\
  % Lolli
  \irb{lolli} \hspace{1em} & : \proc{c}{\trecv{x}{c}{P_x}} \otimes \proc{d}{\tsend{c}{x}{Q_x}{R}} \\
    & \hspace{2em} \lolli \monad{ \exists a. \proc{c}{P_{a}} \otimes \proc{a}{Q_a} \otimes \proc{d}{R} } \\
  % External
  \irb{external} \hspace{1em} & : \proc{c}{\tcase{c}{\tbranches P I}} \otimes \proc{d}{\tselect c i Q} \otimes i \in I \\
    & \hspace{2em} \lolli \monad{ \proc{c}{P_i} \otimes \proc{d}{Q} } \\
\end{align*}
\caption{Substructural operational semantics}
\label{operational}
\end{figure}


\section{Recursion and Subtyping}
\label{recursive}

Any interesting program requires the use of recursion. In fact, we used it even in our first example from the previous section. Here, we formally develop the theory of equirecursive types and recursive processes. We will also introduce (the initial version of) the subtyping judgment which is needed to deal with type equivalences induced by equirecursive types.

\subsection{Recursive Types}

We extend the language of types with a new construct:
\begin{center}
\begin{tabular}{l c l l}
  $A, B, C$ & ::= & \ldots               & everything from before \\
            & $|$ & $t$                  & type variables \\
            & $|$ & $\recursive{t}{A_t}$ & (equi)recursive type
\end{tabular}
\end{center}

Introduction of type variables means not every syntactically valid type makes sense. For example, the type $\recursive t u$ is meaningless since $u$ is not bound anywhere. We will require all types to be closed to rule out such types. This check only needs to happen at the top level since unfolding (which is the only operation we do on recursive types) maintains well-formedness.

We identify recursive types $\recursive{t}{A}$ with their unfolding $\subst{\recursive{t}{A}}{t}{A}$ which means there are no explicit term level coercions ($\mathtt{unfold}$ and $\mathtt{fold}$) to go between the two types. This is the reason they are called equirecursive as opposed to isorecursive where term level coercions would witness the isomorphism. Equirecursive types tend to make type-checking and meta-theory harder, however, they make more sense in a concurrent setting where behavior is easier to rely on than term structure. \todo{Find better explanation. Amadio has a good intro.}

In the style of \cite{AmadioC91}, we interpret recursive types as finite representations of potentially infinite $\mu$-free types through repeated unfolding. For example, the type $\recursive t {\terminate \lolli t}$ stands for $\terminate \lolli (\terminate \lolli (\terminate \lolli (\cdots )))$ and $\recursive t {t \tensor t}$ represents $(\cdots) \tensor (\cdots)$. This interpretation, however, breaks down when we have types such as $\recursive t t$ since no amount of unfolding can remove the $\mu$. To forbid such types, we introduce the standard global syntactic restriction called contractiveness and only consider contractive types from then on.


\subsubsection{Contractiveness}

Intuitively, a recursive type $\recursive t A$ is contractive if all occurrences of $t$ in $A$ are under a \emph{structural} type constructor. For example, $\recursive t {\terminate \lolli t}$ and $\recursive t {t \tensor t}$ are contractive whereas $\recursive t t$ and $\recursive t {\recursive u t}$ are not.

We formalize contractiveness using the notion of unguarded variables \cite{StoneS2005}. Unguarded variables of a type $A$, denoted $\unguarded{(A)}$, are defined inductively as follows:
\begin{align*}
  \unguarded{(\terminate)} &= \emptyset \\
  \unguarded{(A \tensor B)} &= \emptyset \\
  \unguarded{(\internals A I)} &= \emptyset \\
  \unguarded{(A \lolli B)} &= \emptyset \\
  \unguarded{(\externals A I)} &= \emptyset \\
  \unguarded{(t)} &= \set{t} \\
  \unguarded{(\recursive t A)} &= \unguarded{(A)} \setminus \set{t}
\end{align*}

A type is then said to be contractive if every occurrence of $\recursive t A$ satisfies $t \not\in \unguarded{(A)}$.


\subsection{Recursive Processes}

We introduce a new form of process expression which we write $\trec {p} {\tvector c} P_p$ which are modeled after the corecursive processes of \cite{Toninho14}. Here, $p$ is a process variable that intuitively stands for the whole expression and $\tvector c$ is an ordered list of channel names that is used to parametrize the expression over channel names. We use the notation $\tapp P {\tvector c}$ to denote specialization. Parametrization is useful in case we want to rename the provided or used channels. For instance, we will often want to spawn a copy of the overall expression: $\trec p c {\tspawn d {\tapp p d} P_d}$ where $P_d$ is some process that consumes $d$ and offers along $c$. The typing rules limit specialization to recursive processes and process variables.

We also have to extend the typing context to keep track of process variables. Note that we cannot simply add this information to the existing context since that contexts tracks channel names which are different from processes. In addition, the channel context is linear, but there is no reason to limit recursive occurrences of a process to exactly one place. We write the new judgement as $\typeRecDJ P c A$, where $\recCtx$ stores the typing context for process variables. As usual, we assume variable names in $\recCtx$ are made unique through alpha renaming. Recursive processes are typed using the rules in Figure~\ref{recursive-process}. These are the only rules that modify the process variable context, all other rules simply pass it up unchanged.

\begin{rules}[recursive-process]{Type assignment for recursive processes}
  \infer[\rec]{\typeRecDJ {\tapp {\parens*{ \trec p {\tvector y} P}} {\tvector z}} c A}
   { \typeRecD \ctx {\recCtx'} {\subst {\tvector z} {\tvector y} P} c A
   & \recCtx' = \recCtx, \typeD {\subst {\tvector y} {\tvector z} \ctx} {\tvar p {\tvector y}} {\subst {\tvector y} {\tvector z} c} A
   }

   \and \infer[\procVar]{\typeRecD {\rho{\parens \ctx}} \recCtx {\tapp p {\tvector z}} {\rho{\parens c}} A}
    {\typeDJ {\tvar p {\tvector y}} c A \in \recCtx
    & \rho{(\vartheta)} = \subst {\tvector z} {\tvector y} \vartheta
    }
\end{rules}

Note that in the definition of $\recCtx'$, $\typeD {\subst {\tvector y} {\tvector z} \ctx} {\tvar p {\tvector y}} {\subst {\tvector y} {\tvector z} c} A$ is not a typing judgement. Instead, $\recCtx$ should be thought of as nothing more than a map from variable names to four tuples containing parameter names, typing context, provided channel name, and provided type. It is necessary to store the context since channels are linear and channel types evolve over time, but the context needs to be the same at every occurrence of $p$.


\subsection{Subtyping}

Previously, we mentioned we would identify a recursive type and its unfolding, but we have not introduced any formal rules to actually implement this. One way of doing that would be to introduce a type equality judgement (written $A \typeeq B$) and add conversion rules. However, it turns out to be more practical to build this identification into a subtyping judgment (written $A \sub B$) since we already need subtyping for the refinement system (we can define $A \typeeq B$ if and only if $A \sub B$ and $B \sub A$). Subtyping, in turn, serves three purposes: (1) to identify a recursive type and its unfolding, (2) to propagate refinements and forget them as necessary (this will come later), and (3) to admit width and depth subtyping rules for $n$-ary choices which are customary in record-like calculi. The latter two goals overlap since data types are mainly constructed using $n$-ary choices and refinements are useful for describing properties of data types. Before we get into the specifics, let us look at how we make use of subtyping.

As usual, we introduce subtyping into term typing using what are called subsumption rules, which are presented in Figure~\ref{subsumption}. The right rule says that if a process is to provide a type $A$, it can always provide a more specific type $A'$. Dually, the left rule says that if a process can properly handle a more general type $A'$, then it does not hurt to make the type more specific.

\begin{rules}[subsumption]{Subsumption}
  \infer[\irb{Sub}\Right]{\typeRecDJ{P}{c}{A}}
    {\typeRecDJ{P}{c}{A'} & A' \sub A}
  \and \infer[\irb{Sub}\Left]{\typeRecD {\ctx, c : A} \recCtx P d B}
    {\typeD{\ctx, c : A'} P d B & A \sub A'}
\end{rules}

Our subtyping relation is defined coinductively rather than inductively since this admits more subtypes without breaking soundness. Using coinduction means we cannot add reflexivity and transitivity explicitly (subtyping should be a preorder on types), thus we carefully construct the rules to make sure they are admissible. This leads to the semi-algorithmic first attempt given in Figure~\ref{subtyping-first-system} (double lines indicate the rules should be interpreted coinductively). This is only a first attempt since we will have to switch to a related but different system when we add intersections and unions in order to admit (some of the) distributivity laws. \todo{I had a lot more to say about subtyping but I'm already running out of space (see thesis). Is this enough? Should I refer to the thesis?}

\begin{rules}[subtyping-first-system]{Subtyping (first-attempt)}
  % Base types
  \infer=[\Sub{\terminate}]{\terminate \sub \terminate}{}
  \and \infer=[\Sub\tensor]{A \tensor B \sub A' \tensor B'}
    {A \sub A' & B \sub B'}
  \and \infer=[\Sub\internal]{\internals{A}{I} \sub \internals{A'}{J}}
    {I \subseteq J & A_k \sub A'_k~\text{for}~k \in J}
  \and \infer=[\Sub\lolli]{A \lolli B \sub A' \lolli B'}
    {A' \sub A & B \sub B'}
  \and \infer=[\Sub\external]{\externals{A}{I} \sub \externals{A'}{J}}
    {J \subseteq I & A_k \sub A'_k~\text{for}~k \in J}
  % Recursive types
  \\ \infer=[\Sub{\rec\Right}]{A \sub \recursive t B}
    {A \sub \subst {\recursive t B} t B}
  \and \infer=[\Sub{\rec\Left}]{\recursive t A \sub B}
    {\subst {\recursive t A} t A \sub B}
\end{rules}

This concludes the discussion of the base system. In the next section, we introduce intersections, unions, and a multiple conclusion subtyping relation which constitute our main contributions.


\section{Intersections and Unions}
\label{refinements}

Recall our definition of process level naturals $\nat$. One can imagine cases where we would like to know more about the exact nature of the natural. For example, if we are using a natural to track the size of a list, we might want to ensure it is non-zero. Sometimes, it might be relevant to track whether we have an even or an odd number. The system we have described so far turns out to be strong enough to describe all these \emph{refinements} as illustrated below:

\begin{lstlisting}[language=krill, style=custom]
  type Nat = +{zero : 1, succ : Nat}

  type Pos = +{succ : Nat}
  type Even = +{zero : 1, succ : Odd}
  type Odd = +{succ : Even}
\end{lstlisting}

It is easy to see that $\pos$, $\even$, $\odd$ are all subtypes of $\nat$. We run into a problem when we try to implement the behavior described by these types, however. Consider the $\mathtt{suc}$ function, for example, which satisfies many properties: $\nat \lolli \nat$, $\pos \lolli \pos$, $\even \lolli \odd$, $\odd \lolli \even$ etc. Subtyping can be used to combine some of these (e.g.\ $\nat \lolli \pos$ for $\nat \lolli \nat$ and $\pos \lolli \pos$) but it is not strong enough. The usual solution is adding intersections to the type system.


\subsection{Intersection Types}
We denote the intersection of two types $A$ and $B$ as $A \intersect B$ (the more common $\wedge$ was used for value communication). A process offers an intersection type if its behavior satisfies both types simultaneously. Using intersections, we can assign $\mathtt{suc}$ a type specifying all behavioral properties we care about:
$$ \mathtt{suc} : (\nat \lolli \nat) \intersect (\nat \to \pos) \intersect (\even \lolli \odd) \intersect (\odd \lolli \even). $$

Note that as is usual with intersections, multiple types are assigned to \emph{the same process}. Put differently, we cannot use two different processes or specify two different behaviors to satisfy the different branches of an intersection. This leads to the following typing rule on the right:
$$
  \infer[\intersect\Right]{\typeRecDJ{P}{c}{A \intersect B}}
    {\typeRecDJ{P}{c}{A} & \typeRecDJ{P}{c}{B}}
$$

When we are using a channel on the left that offers an intersection of two types, we know it has to satisfy both properties so we get to pick the one we want:
\begin{mathpar}
  \infer[\intersect\Left_1]{\typeRecD{\ctx, c : A \intersect B}{\recCtx}{P}{d}{D}}
    {\typeRecD{\ctx, c : A}{\recCtx}{P}{d}{D}}
  \and \infer[\intersect\Left_2]{\typeRecD{\ctx, c : A \intersect B}{\recCtx}{P}{d}{D}}
    {\typeRecD{\ctx, c : B}{\recCtx}{P}{d}{D}}
\end{mathpar}

The standard semi-algorithmic subtyping rules are given in below. It should be noted that the left rules are derivable by an application of subsumption on the left using $\Sub{\intersect\Left_1}$ and $\Sub{\intersect\Left_2}$, so we will not explicitly add them to the final system. Also, we will have to modify the subtyping relation later in this section, so the subtyping rules are still a first attempt.

\begin{mathpar}
  \infer=[\Sub{\intersect}\Right]{A \sub B_1 \intersect B_2}
    {A \sub B_1 \and A \sub B_2}
  \and \infer=[\Sub{\intersect\Left_1}]{A_1 \intersect A_2 \sub B}
    {A_1 \sub B}
  \and \infer=[\Sub{\intersect\Left_2}]{A_1 \intersect A_2 \sub B}
    {A_2 \sub B}
\end{mathpar}

Finally, we need to extend the definition of unguarded variables and contractiveness. Since $\intersect$ is not a structural type, it simply combines and propagates unguarded variables:
$$ \unguarded{(A \intersect B)} &= \unguarded{(A)} \cup \unguarded{(B)}. $$


\subsection{Union Types}

Unions are the dual of intersections and correspond to processes that satisfy one or the other property, and are written $A \union B$. We add unions because they are a natural extension to a  type system with intersections. We will also see how $n$-ary internal choice can be interpreted as
the union of singleton choices. Without them, our interpretation would only be half-complete since we could interpret external choice (with intersections) but not internal choice.

Being dual to intersections, the typing rules for unions mirror the typing rules for intersections: we have two right rules and one left rule, and this time the right rules are derivable from subtyping. The rules are given below:

\begin{mathpar}
  \infer[\union\Right_1]{\typeRecDJ{P}{c}{A \union B}}
    {\typeRecDJ{P}{c}{A}}
  \and \infer[\union\Right_2]{\typeRecDJ{P}{c}{A \union B}}
    {\typeRecDJ{P}{c}{B}}
  \and \infer[\union\Left]{\typeD{\ctx, c : A \union B}{\recCtx}{P}{d}{D}}
    {\typeD{\ctx, c : A}{P}{d}{D} & \typeD{\ctx, c : B}{\recCtx}{P}{d}{D}}
\end{mathpar}

The right rules say the process has to offer either the left type or the right type respectively. The left rule says we need to be prepared to handle either type. We would like to note that we restore a symmetry in this system that has been long lost for functional languages. The natural left rule we give here for unions (natural since it mirrors the right rule for intersection as it should) has been shown to be unsound in functional languages with effects \todo{Find citation}. Reconciling unions with effects requires complicated concepts such as an evaluation context and tridirectional type-checking \todo{citation}. The reason is that the typing rule only checks the cases where \emph{all} occurrences of a variable have the first type or all have the second type, however, it could be the case that some have the first and others have the second in the presence of effects. This cannot be the case here because our language almost acts like a lazy purely-functional language, and more importantly, linearity assures each channel is used once \todo{Not exactly once but close enough. Maybe the reason is it acts like the channel is always in an evaluation context?}

The usual subtyping rules are given below. These make the right rules derivable so they are not explicitly added to the system.

\begin{mathpar}
  \infer=[\Sub{\union\Right_1}]{A \sub B_1 \union B_2}
    {A \sub B_1}
  \and \infer=[\Sub{\union\Right_1}]{A \sub B_1 \union B_2}
    {A \sub B_2}
  \and \infer=[\Sub{\union\Left}]{A_1 \union A_2 \sub B}
    {A_1 \sub B & A_2 \sub B}
\end{mathpar}

Unguarded variables of union is the same as intersection:
$$ \unguarded{(A \union B)} &= \unguarded{(A)} \cup \unguarded{(B)}. $$


\subsection{Top and Bottom}

$\bot$ is the unit for internal choice and union. $\top$ is the unit for external choice and intersection.


\subsection{Subtyping Revisited}

In line with our propositional interpretation of intersections and unions, one would naturally expect the usual properties of these to hold in our system. For example, unions should distribute over intersections and vice versa, that is, the following equalities should be admissible:
\begin{mathpar}
   (A_1 \union B) \intersect (A_2 \union B) \typeeq (A_1 \intersect A_2) \union B \\
   (A_1 \union A_2) \intersect B \typeeq (A_1 \intersect B) \union (A_2 \intersect B)
\end{mathpar}

Going from right to left turns out to be easy, but we quickly run into a problem if we try to do the other direction: whether we break down the union on the right or the intersection on the left, we always lose half the information we need to carry out the rest of the proof.%
\footnote{This issue does not come up in the other direction since intersection right and union left rules are invertible, that is, they preserve all information.}%
We think the fact that the equality holds in the other direction only exacerbates the problem, since it means the way we write down types and where types happen to occur actually matters, which will inevitable lead to unintuitive type-checker errors.

Our solution is doing the obvious: if the problem is losing half the information, well, we should just keep it around. This suggests a system where the single type on the left and on the type right are replaced with \emph{(multi)sets} of types. That is, instead of the judgment $A \le B$, we use a judgement of the form $A_1, \ldots, A_n \subA B_1, \ldots, B_n$, where the left of $\subA$ is interpreted as a conjunction (intersection) and the right is interpreted as a disjunction (union).\todo{Explain why it is conjunction and disjunction?} This results in a system reminiscent of \cite{Gentzen35, Girard87}. However, we take a slightly different approach since we are working with coinductive rules.

The rules are given in Figure~\ref{subtyping-multi}. We use $\typeList$ and $\typeListB$ to denote multisets of types. The intersection left rules are combined into one rule that keeps both branches around. The same is done with union right rules. Intersection right and union left rules split into two derivations, one for each branch, but keeping the rest of the types unchanged. We can unfold a recursive type on the left or on the right. When we choose to apply a structural rule, we have to pick exactly one type on the left and one type on the right with the same structure. Note that this is not an essential restriction. In fact, we predict that matching multiple types will give us distributivity of intersection and union over structural types, which is desirable. \todo{Give examples?} We have to be careful not to admit unsound judgements, and it makes the system more complicated, so we not explore that route in this paper. \todo{Interested readers are directed to the first author's thesis.} \todo{Split the rules into property and rest?}

\begin{rules}[subtyping-multi]{Subtyping with multiple hypothesis and conclusions}
  % Intersection
  \infer=[\SubA{\intersect}\Right]{\typeList \subA \typeListB, A_1 \intersect A_2}
    {\typeList \subA \typeListB, A_1 \and \typeList, A \subA \typeListB, A_2}
  \and \infer=[\SubA{\intersect}\Left]{\typeList, A_1 \intersect A_2 \subA \typeListB}
    {\typeList, A_1, A_2 \subA \typeListB}
  % Union
  \\ \infer=[\SubA{\union}\Right]{\typeList \subA \typeListB, A_1 \union A_2}
    {\typeList \subA \typeListB, A_1, A_2}
  \and \infer=[\SubA{\union}\Left]{\typeList, A_1 \union A_2 \subA \typeListB}
    {\typeList, A_1 \subA \typeListB, B & \typeList, A_2 \subA \typeListB}
  % Structural
  \\ \infer=[\SubA{\terminate}]{\typeList, \terminate \subA \typeListB, \terminate}{}
  \and \infer=[\SubA\tensor]{\typeList, A \tensor B \subA \typeListB, A' \tensor B'}
    {A \subA A' & B \subA B'}
  \and \infer=[\SubA\internal]{\typeList, \internalSing{\lab}{A} \subA \typeListB, \internalSing{\lab}{A'}}
    {A \subA A'}
  \and \infer=[\SubA\lolli]{\typeList, A \lolli B \subA \typeListB, A' \lolli B'}
    {A' \subA A & B \subA B'}
  \and \infer=[\SubA\external]{\typeList, \externalSing{\lab}{A} \subA \typeListB, \externalSing{\lab}{A'}}
    {A \subA A'}
  % Recursive
  \\ \infer=[\SubA{\mu\Right}]{\typeList \subA \typeListB, \recursive t A}
     {\typeList \subA \typeListB, \subst {\recursive t A} t A}
  \and \infer=[\SubA{\mu\Left}]{\typeList, \recursive t A \subA \typeListB}
     {\typeList, \subst {\recursive t A} t A \subA \typeListB}
\end{rules}


\subsection{Subtyping Extra Material}

\todo{Decide if we want to use anything from this subsection.}
The subtyping relation we gave before is not complete with respect to, say, the ideal semantics of types \cite{VouillonM04, Damm94}. This is because intersections and unions admit many distributivity-like rules over structural types and over each other. For example, it is not hard to see that $(A_1 \tensor A_2) \intersect (B_1 \tensor B_2) \sub (A_1 \intersect B_1) \tensor (A_2 \intersect B_2)$ would be sound using a propositional reading: if a process sends out a channel that satisfies $A_1$ then acts as $B_1$, \emph{and} the sent channel also satisfies $A_2$ in addition to the result satisfying $B_2$, then the channel satisfies both $A_1$ and $A_2$ and the result satisfies both $B_1$ and $B_2$. However, this judgement is not admissible in the given system: the only applicable rules are $\Sub{\intersect\Left_1}$ and $\Sub{\intersect\Left_2}$, both of which get stuck because we lose half the information we require for the rest of the derivation. The situation is perhaps exacerbated by the fact that we \emph{can} prove subtyping in the other direction, so these types are supposed to be equivalent. This means depending on where these types occur, we may fail to prove one side of a symmetric relation!

The fix is not as simple as adding this rule as an extra axiom. For one, it is not trivial to rewrite this rule in order to preserve admissibility of transitivity. More importantly, this is not the only rule we would have to add. Figure~\ref{distributivity-examples} gives just \emph{some} of the many sound rules that are not admissible.

\begin{rules}[distributivity-examples]{Sound but inadmissible subtyping rules}
   % Intersection
   (A_1 \tensor A_2) \intersect (B_1 \tensor B_2) \sub (A_1 \intersect B_1) \tensor (A_2 \intersect B_2) \\
   \internals A I \intersect \internals B J \sub \internal\braces{\lab_x : A_x \intersect B_x}_{x \in I \cap J} \\
   (A \lolli B_1) \intersect (A \lolli B_2) \sub A \lolli (B_1 \intersect B_2) \\
   \externals A I \intersect \externals B J \sub \externals A I \cup \externals B J ~ (I \cap J = \emptyset)\\
   % Union
   (A_1 \union A_2) \tensor B \sub (A_1 \tensor B) \union (A_2 \tensor B) \\
   \internals A I \cup \internals B J \sub \internals A I \union \internals B J ~ (I \cap J = \emptyset) \\
   (A_1 \lolli B) \intersect (A_2 \lolli B) \sub (A_1 \union A_2) \lolli B \\
   \external\braces{\lab_x : A_x \union B_x}_{x \in I \cap J} \sub \externals A I \union \externals B J \\
   % Intersection and union
   (A_1 \union B) \intersect (A_2 \union B) \sub (A_1 \intersect A_2) \union B \\
   (A_1 \union A_2) \intersect B \sub (A_1 \intersect B) \union (A_2 \intersect B)
\end{rules}

This list is certainly not complete, and there are almost as many rules in this list as there are in the original system. Clearly, a blind axiomatic approach which adds all admissible rules is not practical and a more general treatment is in order. There has been some work in incorporating intersections and unions in a conventional type system that preserves completeness under certain conditions. The closest and most complete system we found was from Damm (\cite{Damm94, Damm94p2}). In \cite{Damm94}, he encodes types as regular tree expressions, and reformulates subtyping as regular tree grammar containment which was shown to be decidable. This results in a system that is sound and complete when all types are infinite (but $\terminate$ is a finite type). \cite{Damm94p2} extends this work such that the system is sound in the presence of finite types (although not necessarily complete).

Their system is very close to what we would like to accomplish, however, we think it is too complicated for our purposes as it requires familiarity with ideal semantics of types (which in turn is based on domain theory and the theory metric spaces) and regular tree grammars. Even if a similar approach could be made to work, we find such systems to be fragile in the face of future extensions. We would rather work with a simple and robust subtyping relation that does not necessitate rethinking every detail with every extension, so we make a design decision: we give up full completeness and instead design a system that admits the rules we are likely to encounter in practice.


\subsection{Refinement Example}
\todo{We did promise.}


\subsection{Reinterpreting Choice}

\todo{Compile choice.}




\section{Metatheory}
\label{metatheory}

\todo{Talk a little about this stuff.}

\todo{See thesis for the proofs. Should we add them here, in the appendix, or just gloss over them?}

\begin{theorem}[Progress]
If $\providesCtx \config \ctx$ then either
\begin{enumerate}
  \item $\steps{\config}{\config'}$ for some $\config'$, or
  \item $\config$ is poised.
\end{enumerate}
\end{theorem}


\begin{theorem}[Preservation]
If $\providesCtx \config \ctx$ and $\steps{\config}{\config'}$ then $\providesCtx {\config'} \ctx$.
\end{theorem}


\section{Algorithmic System}
\label{algorithmic}

To show that our system is practical, we would like to show that subtyping and type-checking are decidable. We do this by designing an algorithm that takes in a (sub)typing judgement and produces true if there is a derivation in the system and false otherwise. Note that everything in the judgement is considered an input, that is, the interface for the algorithms are $\typeList^+ \subA \typeListB^+$ and $\typeRecD {\ctx^+} {\recCtx^+} {P^+} {c^+} {A^+}$, respectively (where $^+$ indicates input and non-existent $^-$ indicates output). \todo{Probably don't need the last sentence.}


\subsection{Algorithmic Subtyping}

The subtyping judgement we gave is already mostly algorithmic (since we are working with coinductive rules), so we only have a couple loose-ends to tie up. The first is the question of which rule to apply when multiple are applicable. Unfortunately, we have to try all possibilities non-deterministically since anyone could work. One optimization we can do is to apply $\SubA{\intersect\Right}$, $\Sub{\intersect\Left}$, $\SubA{\union\Right}$, $\Sub{\union\Left}$, $\SubA{\mu\Right}$, $\SubA{\mu\Left}$ eagerly since these rules are invertible. At some point, we must hit all structural types due to our contractiveness restriction, at which point we non-deterministically pick a structure and continue. \todo{Citation?}

The coinductive nature of typing means we can (and often will) have infinite derivations. This raises the question of how we can have a finite time algorithm. We use a slightly modified version of the algorithm given in \cite{GayH05}. The idea is simple: we maintain a context of previously seen subtyping checks and immediately terminate with success if we ever compare the same pair of sets of types again. Since every recursive step corresponds to a rule, the generated derivation must be productive. We know there cannot be an infinite chain due to the contractiveness restriction. A more formal treatment can be found in \cite{StoneS2005}.

Now that we have an algorithm for subtyping, the next step is to come up with an algorithm for type checking.


\subsection{Algorithmic Type-checking}

Designing a type checking algorithm is quite simple for the base system where we only have structural types (no recursion or subtyping), since the form of the process determines a unique applicable typing rule. The $\cut$ rule causes a small problem since we do not have a type for the helper process to check against. This is solved by adding type annotations in spawning processes (but nowhere else) so that the new form is $\tspawnType c {P_c} A {Q_c}$. We define $\erase{P}$ to be $P$ with all type annotations erased.

In the extended system with subtyping and property types, type-checking is a lot trickier for two reasons: (1) subsumption can be applied anytime where one of the types in $A \le B$ is free (meaning it can be anything), and (2) intersection left and union right rules lose information which means they have to be applied non-deterministically. The latter issue is resolved by switching to a multiset context multiple conclusion logic just like we did with subtyping. This makes intersection left and union right rules invertible, so they can be applied eagerly.

The former problem is solved by switching to \emph{bidirectional type-checking} where we only need to check subtyping when we do a forward. This relies on the following crucial observation: if we are checking a process against a structural type, the subparts of $P$ must check against subparts of $A$. For example, if we are checking $\tsend c d {P_d} Q$ against $c : A \tensor B$, then $P_d$ must check against $d : A$ and $Q$ must check against $c : B$. Even if we could use subsumption, $\tsend c d {P_d} Q$ would still have to type-check against a type $c : A' \tensor B' \sub A \tensor B$ which would imply $A' \sub A$ and $B' \sub B$. \todo{Kinda messed this up. Better explanation.} To make sure we can always get down to structural types, we add unfolding rules on the right and on the left, and apply these eagerly along with rules for intersections and unions.

\todo{Talk about soundness and completeness.}

The final system is given in \todo{Rules for the final system}.


\section{Conclusion}
\label{conclusion}

Future work:
Polymorphism, type inference, abstract types, top, bottom.


\appendix


%%
%% Bibliography
%%

\todo{Somehow shrink the citations. Maybe get rid of the urls.}

\bibliography{bibliography}



\end{document}
